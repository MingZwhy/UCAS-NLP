<center><font size="5">NLPç¬¬å››æ¬¡å¤§ä½œä¸šå®éªŒæŠ¥å‘Š</font></center>

<div style="text-align: right;">é™ˆè¿œè…¾ 2020k8009929041</div>

[toc]

## ä¸€ã€é€‰é¢˜

5.åˆ©ç”¨å…¬å¼€çš„æƒ…æ„Ÿæˆ–æƒ…ç»ªåˆ†æè¯„æµ‹è¯­æ–™ï¼Œå¯¹æ¯”åˆ†æç»Ÿè®¡å­¦ä¹ æ–¹æ³•å’Œç¥ç»ç½‘ç»œæ–¹æ³•çš„æ€§èƒ½å·®å¼‚ï¼Œå¹¶è¿›è¡Œé”™è¯¯åˆ†æã€‚



## äºŒã€ç¯å¢ƒæ­å»º

### 1.å®¹å™¨ç¯å¢ƒå‡†å¤‡

ç”±äºæˆ‘ä»¬å¸Œæœ›è®­ç»ƒåŸºäºtransformerçš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹ï¼Œå¯¹æ˜¾å­˜è¦æ±‚è¾ƒé«˜ï¼Œæœ¬æœºçš„GPUæ— æ³•æ»¡è¶³ï¼Œå› æ­¤æˆ‘åœ¨autodlå¹³å°ä¸Šç§Ÿèµäº†4 x RTX3090 çš„æœåŠ¡å™¨å®¹å™¨ï¼Œä½œä¸ºæœ¬æ¬¡å®éªŒçš„å¹³å°ã€‚ï¼ˆå®é™…ä¸Šæ˜¯æ²¿ç”¨äº†ç¬¬ä¸‰æ¬¡å¤§ä½œä¸šæ‰€ä½¿ç”¨çš„ç¯å¢ƒï¼‰

![image-20230701100920194](D:/Work_Program/Typora/image/image-20230701100920194.png)



### 2.ä¾èµ–åº“ä¸ç›¸å…³å·¥å…·å®‰è£…

æœ¬æ¬¡å®éªŒåœ¨ç¥ç»ç½‘ç»œæ–¹æ³•æ–¹é¢ï¼Œæˆ‘ä½¿ç”¨hugging faceæä¾›çš„transformeræ¡†æ¶ï¼š

é“¾æ¥ï¼š<[GitHub - huggingface/transformers: ğŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.](https://github.com/huggingface/transformers)>

ç®€è¦ä»‹ç»ï¼ˆå…·ä½“å†…å®¹è¯·è§ä»¥ä¸Šä»“åº“çš„è¯´æ˜æ–‡æ¡£ï¼‰ï¼š

Hugging Face Transformersæ˜¯ä¸€ä¸ªç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„å¼€æºåº“ï¼Œæ—¨åœ¨æä¾›ä¸€ç§ç®€å•è€Œå¿«é€Ÿçš„æ–¹å¼æ¥æ„å»ºã€è®­ç»ƒå’Œéƒ¨ç½²å„ç§NLPæ¨¡å‹ã€‚è¯¥åº“çš„æ ¸å¿ƒæ˜¯ä½¿ç”¨PyTorchå’ŒTensorFlow 2.0å®ç°çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹å¯ä»¥ç”¨æ¥è¿›è¡Œå„ç§NLPä»»åŠ¡ï¼Œä¾‹å¦‚æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€è¯­è¨€ç¿»è¯‘å’Œé—®ç­”ç­‰ã€‚

Transformersåº“æä¾›äº†ä¸€ä¸ªé«˜çº§åˆ«çš„APIï¼Œä½¿å¾—ä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹å˜å¾—å¼‚å¸¸ç®€å•ï¼ŒåŒæ—¶ä¹Ÿæä¾›äº†ä½çº§åˆ«çš„APIï¼Œä½¿å¾—ç”¨æˆ·å¯ä»¥å¯¹æ¨¡å‹è¿›è¡Œæ›´åŠ ç»†ç²’åº¦çš„æ§åˆ¶ã€‚åœ¨ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©ä½¿ç”¨å·²ç»è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥é€šè¿‡å¾®è°ƒå·²æœ‰çš„æ¨¡å‹æˆ–ä½¿ç”¨è‡ªå·±çš„æ•°æ®è¿›è¡Œè®­ç»ƒã€‚

é™¤äº†é¢„è®­ç»ƒæ¨¡å‹ä¹‹å¤–ï¼ŒHugging Face Transformersè¿˜æä¾›äº†å„ç§NLPä»»åŠ¡çš„æ•°æ®é›†å’Œè¯„ä¼°æŒ‡æ ‡ï¼Œè¿™äº›å¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´å¥½åœ°ç†è§£å’Œè¯„ä¼°ä»–ä»¬çš„æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°ã€‚



ç¯å¢ƒæ­å»ºå‘½ä»¤ï¼š

```shell
# åˆ›å»ºæ–°çš„è™šæ‹Ÿç¯å¢ƒbert
conda create -n bert python=3.8
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
conda activate bert
# å®‰è£…pytorch (æˆ‘çš„æœåŠ¡å™¨ä¸ŠCUDAç‰ˆæœ¬ä¸º11.3ï¼Œå¦‚å…¶ä»–ç‰ˆæœ¬è¯·å‚è€ƒPytorchå®˜ç½‘è¿›è¡Œå®‰è£…)
conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.3 -c pytorch
# å®‰è£…transformersåº“æ–¹æ³•1 (pip)
pip install transformers
# å®‰è£…transformersåº“æ–¹æ³•2 (conda)
conda install -c huggingface transformers

# å®‰è£…æ•°æ®é›†æ‰€éœ€åº“datasets
pip install datasets
# å®‰è£…è¯„ä¼°åº“evaluate
pip install evaluate
# å‡çº§accelerateåº“
pip install --upgrade accelerate

# å®‰è£…ä¼ ç»Ÿæ–¹æ³•æ‰€ç”¨çš„sklearnåº“
pip install -U scikit-learn
```



## ä¸‰ã€å®éªŒè¿‡ç¨‹

### 1.æ•°æ®é›†å‡†å¤‡

```python
from datasets import load_dataset
dataset = load_dataset("yelp_review_full")
```

è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨Hugging Face Datasetsåº“ä¸­çš„`load_dataset`æ–¹æ³•åŠ è½½Yelp Review Fullæ•°æ®é›†ï¼š

`yelp_review_full`æ•°æ®é›†æ˜¯ä¸€ä¸ªå…³äºé¤å…è¯„è®ºçš„æ•°æ®é›†ï¼ŒåŒ…å«æ¥è‡ªYelpç½‘ç«™çš„è¶…è¿‡500,000æ¡è‹±æ–‡è¯„è®ºã€‚è¿™äº›è¯„è®ºè¢«åˆ†ä¸ºäº”ä¸ªç±»åˆ«ï¼ˆ1-5æ˜Ÿï¼‰ï¼Œå…¶ä¸­1æ˜Ÿè¡¨ç¤ºéå¸¸å·®ï¼Œ5æ˜Ÿè¡¨ç¤ºéå¸¸å¥½ã€‚æ•°æ®é›†ä¸­çš„è¯„è®ºå…·æœ‰ä¸åŒé•¿åº¦å’Œä¸»é¢˜ï¼ŒåŒ…æ‹¬é£Ÿç‰©ã€æœåŠ¡ã€ä»·æ ¼ç­‰ã€‚è¿™ä¸ªæ•°æ®é›†é€šå¸¸ç”¨äºæ–‡æœ¬åˆ†ç±»å’Œæƒ…æ„Ÿåˆ†æä»»åŠ¡ã€‚åŠ è½½åè¿”å›ä¸€ä¸ªå­—å…¸å¯¹è±¡ï¼Œå…¶ä¸­åŒ…å«â€œtrainâ€ã€â€œtestâ€å’Œâ€œvalidationâ€ä¸‰ä¸ªé”®ï¼Œæ¯ä¸ªé”®å¯¹åº”ç€ä¸€ä¸ªæ•°æ®é›†åˆ†å‰²ã€‚æ¯ä¸ªåˆ†å‰²éƒ½æœ‰â€œtextâ€å’Œâ€œlabelâ€ä¸¤ä¸ªå­—æ®µï¼Œå…¶ä¸­â€œtextâ€å­—æ®µåŒ…å«è¯„è®ºæ–‡æœ¬ï¼Œè€Œâ€œlabelâ€å­—æ®µåŒ…å«è¯„è®ºçš„æ˜Ÿçº§è¯„åˆ†ã€‚

è¿™é‡Œæˆ‘ä»¬æˆªå–è®­ç»ƒé›†çš„å‰ä¸‰æ¡æ–‡æœ¬åŠå…¶å¯¹åº”æ ‡ç­¾å±•ç¤ºå¦‚ä¸‹ï¼š

![image-20230702101251800](D:/Work_Program/Typora/image/image-20230702101251800.png)

å¯ä»¥çœ‹åˆ°ï¼Œè®­ç»ƒé›†çš„å‰ä¸‰æ¡æ–‡æœ¬çš„æ ‡ç­¾åˆ†åˆ«ä¸º4,1,3ã€‚

<table><tr><td bgcolor=#FAEBD7>åç»­æˆ‘ä»¬å°†åŸºäºYelp Review Fullæ•°æ®é›†è®­ç»ƒäº”åˆ†ç±»çš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹ã€‚



### 2.æ•°æ®é¢„å¤„ç†

ä¸ä¹‹å‰çš„ä»»åŠ¡ç›¸åŒï¼Œåœ¨è®­ç»ƒæ¨¡å‹å‰ï¼Œé¦–å…ˆéœ€è¦å¯¹åŸå§‹æ•°æ®é›†åšæ•°æ®é¢„å¤„ç†ï¼Œä¾‹å¦‚åˆ†è¯ï¼š

è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨transformersåº“æä¾›çš„AutoTokenizerå·¥å…·å¯¹åŸå§‹æ•°æ®é›†è¿›è¡Œåˆ†è¯å¤„ç†ï¼Œé€‰å–çš„è®­ç»ƒå¥½çš„åˆ†è¯æ¨¡å‹ä¸ºhugging faceæä¾›çš„ "bert-base-cased"ã€‚

```python
# å¯¼å…¥AutoTokenizeråº“
from transformers import AutoTokenizer
# åŠ è½½é¢„è®­ç»ƒåˆ†è¯æ¨¡å‹tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")

# å®šä¹‰åˆ†è¯å‡½æ•°ï¼Œä¸ºåç»­mapåšå‡†å¤‡
def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)

# å¯¹åŸå§‹æ•°æ®é›†è¿›è¡Œåˆ†è¯é¢„å¤„ç†
tokenized_datasets = dataset.map(tokenize_function, batched=True)
```



åˆ†è¯åæ•ˆæœå¦‚ä¸‹ï¼š

![image-20230702101930154](D:/Work_Program/Typora/image/image-20230702101930154.png)

å¯ä»¥çœ‹åˆ°ï¼Œè®­ç»ƒé›†ä¸Šæœ‰650000æ¡æ–‡æœ¬æ•°æ®ï¼Œè€Œæµ‹è¯•é›†ä¸Šæœ‰50000æ¡æ–‡æœ¬æ•°æ®ã€‚

<table><tr><td bgcolor=#FAEBD7>ç”±äºæˆ‘ä»¬çš„è®¡ç®—èµ„æºæœ‰é™ï¼Œå› æ­¤è¿™é‡Œåªæˆªå–è®­ç»ƒé›†ä¸Šå‰10000æ¡æ–‡æœ¬ä½œä¸ºæˆ‘ä»¬çš„è®­ç»ƒé›†ï¼Œæˆªå–æµ‹è¯•é›†ä¸Šå‰2000æ¡æ–‡æœ¬ä½œä¸ºæˆ‘ä»¬çš„æµ‹è¯•é›†ï¼š

```python
small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(10000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(2000))
```



### 3.ä¼ ç»Ÿæ–¹æ³•

#### (1)åŸºäºå†³ç­–æ ‘çš„æ–‡æœ¬åˆ†ç±»

åŸºäºä¼ ç»Ÿæ–¹æ³•çš„æ–‡æœ¬åˆ†ç±»ï¼Œæˆ‘ä»¬é¦–å…ˆæƒ³åˆ°äº†å†³ç­–æ ‘çš„æ–¹æ³•ï¼š

```python
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from datasets import Dataset

# è·å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç‰¹å¾å’Œæ ‡ç­¾
train_features = small_train_dataset['text']
train_labels = small_train_dataset['label']
test_features = small_eval_dataset['text']
test_labels = small_eval_dataset['label']

# ç‰¹å¾æå–
vectorizer = CountVectorizer(max_features=1000)
train_features_vectorized = vectorizer.fit_transform(train_features)
test_features_vectorized = vectorizer.transform(test_features)

# è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹
clf = DecisionTreeClassifier()
clf.fit(train_features_vectorized, train_labels)

# åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹å¹¶è¯„ä¼°æ¨¡å‹æ€§èƒ½
pred_labels = clf.predict(test_features_vectorized)
accuracy = accuracy_score(test_labels, pred_labels)
report = classification_report(test_labels, pred_labels)
print('Accuracy:', accuracy)
print('Classification report:\n', report)
```

åˆ†ç±»ç»“æœåŠé”™è¯¯åˆ†æå¦‚ä¸‹ï¼š

![image-20230702104901635](D:/Work_Program/Typora/image/image-20230702104901635.png)

å¯ä»¥çœ‹åˆ°ä½¿ç”¨å†³ç­–æ ‘çš„æ–¹æ³•è¿›è¡Œæ–‡æœ¬åˆ†ç±»çš„å‡†ç¡®ç‡éå¸¸ä½ï¼Œåªæœ‰33.81%ï¼Œåœ¨é”™è¯¯åˆ†æä¸­ï¼Œæˆ‘ä»¬å‘ç°ï¼š

* å¯¹äºè¾ƒæç«¯çš„è¯„ä»·æ–‡æœ¬(label = 0 æˆ– label = 4)ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡å’Œå¬å›ç‡éƒ½åœ¨40%ä»¥ä¸Šï¼Œå› ä¸ºè¿™äº›æ–‡æœ¬çš„æƒ…æ„Ÿæ¯”è¾ƒå¼ºçƒˆï¼Œæ¯”è¾ƒå®¹æ˜“è¾¨è¯†ã€‚
* è€Œå¯¹äºè¾ƒä¸­ç«‹çš„è¯„ä»·æ–‡æœ¬(label = 1 æˆ– label = 2 æˆ– label = 3)ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡å’Œå¬å›ç‡éƒ½åœ¨30%ä»¥ä¸‹ï¼Œå› ä¸ºè¿™ä¸ªæ–‡æœ¬çš„æƒ…æ„Ÿè¾ƒæ¨¡ç³Šï¼Œä¸æ˜“è¾¨è¯†ã€‚



#### (2)åŸºäºè´å¶æ–¯çš„æ–‡æœ¬åˆ†ç±»

å…¶æ¬¡ï¼Œæˆ‘æƒ³åˆ°äº†ä½¿ç”¨è´å¶æ–¯åˆ†ç±»æ¨¡å‹ï¼š

```python
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# è·å–è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç‰¹å¾å’Œæ ‡ç­¾
train_features = small_train_dataset['text']
train_labels = small_train_dataset['label']
test_features = small_eval_dataset['text']
test_labels = small_eval_dataset['label']

# ç‰¹å¾æå–
vectorizer = CountVectorizer(max_features=1000)
train_features_vectorized = vectorizer.fit_transform(train_features)
test_features_vectorized = vectorizer.transform(test_features)

# è®­ç»ƒæœ´ç´ è´å¶æ–¯æ¨¡å‹
clf = MultinomialNB()
clf.fit(train_features_vectorized, train_labels)

# åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹å¹¶è¯„ä¼°æ¨¡å‹æ€§èƒ½
pred_labels = clf.predict(test_features_vectorized)
accuracy = accuracy_score(test_labels, pred_labels)
report = classification_report(test_labels, pred_labels)
print('Accuracy:', accuracy)
print('Classification report:\n', report)
```

åˆ†ç±»ç»“æœåŠé”™è¯¯åˆ†æå¦‚ä¸‹ï¼š

![image-20230702105454615](D:/Work_Program/Typora/image/image-20230702105454615.png)



å¯ä»¥çœ‹åˆ°ä½¿ç”¨è´å¶æ–¯çš„æ–¹æ³•è¿›è¡Œæ–‡æœ¬åˆ†ç±»çš„å‡†ç¡®ç‡è¾ƒå†³ç­–æ ‘è€Œè¨€æœ‰ä¸€å®šæå‡ï¼Œè¾¾åˆ°äº†50.22%ï¼Œåœ¨é”™è¯¯åˆ†æä¸­ï¼Œæˆ‘ä»¬å‘ç°ç°è±¡ä¸å†³ç­–æ ‘æ¯”è¾ƒç›¸ä¼¼ï¼š

* å¯¹äºè¾ƒæç«¯çš„è¯„ä»·æ–‡æœ¬(label = 0 æˆ– label = 4)ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡å’Œå¬å›ç‡éƒ½åœ¨60%å·¦å³ï¼Œå› ä¸ºè¿™äº›æ–‡æœ¬çš„æƒ…æ„Ÿæ¯”è¾ƒå¼ºçƒˆï¼Œæ¯”è¾ƒå®¹æ˜“è¾¨è¯†ã€‚
* è€Œå¯¹äºè¾ƒä¸­ç«‹çš„è¯„ä»·æ–‡æœ¬(label = 1 æˆ– label = 2 æˆ– label = 3)ï¼Œæ¨¡å‹çš„å‡†ç¡®ç‡å’Œå¬å›ç‡éƒ½åœ¨40%å·¦å³ï¼Œå› ä¸ºè¿™ä¸ªæ–‡æœ¬çš„æƒ…æ„Ÿè¾ƒæ¨¡ç³Šï¼Œä¸æ˜“è¾¨è¯†ã€‚



### 4.ç¥ç»ç½‘ç»œæ–¹æ³•

ç¥ç»ç½‘ç»œæ–¹æ³•æ–¹é¢ï¼Œæˆ‘ä»¥hugging faceæä¾›çš„Berté¢„è®­ç»ƒæ¨¡å‹ä¸ºåŸºç¡€ï¼Œåœ¨Yelp Review Fullæ•°æ®é›†ä¸Šè¿›è¡Œfine-tuneè®­ç»ƒäº”åˆ†ç±»çš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹ï¼š

* é¢„è®­ç»ƒæ¨¡å‹åŠ è½½ï¼š

  ```python
  from transformers import AutoModelForSequenceClassification
  model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)
  ```

* ä¼˜åŒ–å™¨ï¼šAdam
* è¯„ä¼°æ ‡å‡†ï¼šloss + accuracy
* fine-tuneè½®æ•°ï¼šepoch = 10



è®­ç»ƒç»“æœï¼š

![image-20230702103043406](D:/Work_Program/Typora/image/image-20230702103043406.png)

æµ‹è¯•é›†ä¸Šçš„lossæ›²çº¿å¦‚ä¸‹ï¼š

![loss_curve](D:/Work_Program/Typora/image/loss_curve-1688265726175-1.png)

å¯ä»¥çœ‹åˆ°ï¼Œåœ¨ç¬¬2ä¸ªepochå¤„æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„losså°±åŸºæœ¬åˆ°è¾¾äº†æœ€ä½ï¼Œå‡†ç¡®ç‡è¾¾åˆ°60%å·¦å³ã€‚ç¬¬äºŒä¸ªepochåå‡ºç°äº†è¿‡æ‹Ÿåˆç°è±¡ï¼Œåœ¨æµ‹è¯•é›†ä¸Šçš„lossé€æ¸å‡é«˜ã€‚

<table><tr><td bgcolor=#FAEBD7>å¯ä»¥çœ‹åˆ°ç»è¿‡fine-tuneï¼Œæ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡ç”±56%æå‡åˆ°äº†60%å·¦å³ã€‚è¡¨ç°æ˜æ˜¾å¥½äºä¼ ç»Ÿæ–¹æ³•(å†³ç­–æ ‘å’Œè´å¶æ–¯åˆ†ç±»)ã€‚



## å››ã€ç»“æœå¯¹æ¯”

æ ¹æ®ä»¥ä¸Šå®éªŒç»“æœï¼Œæˆ‘ä»¬å°†ä¼ ç»Ÿæ–¹æ³•å’Œç¥ç»ç½‘ç»œæ–¹æ³•çš„ç»“æœå·¦ä»¥ä¸‹å¯¹æ¯”ï¼š

| åˆ†ç±»æ–¹æ³•               | å‡†ç¡®ç‡ | rank |
| ---------------------- | ------ | ---- |
| å†³ç­–æ ‘                 | 33.81% | 3    |
| è´å¶æ–¯                 | 50.22% | 2    |
| Berté¢„è®­ç»ƒ + fine-tune | 60.20% | 1    |

å¯ä»¥çœ‹åˆ°ï¼ŒåŸºäºç¥ç»ç½‘ç»œçš„æ–‡æœ¬åˆ†ç±»æ¨¡å‹è·å¾—äº†æœ€å¥½çš„è¡¨ç°ã€‚
