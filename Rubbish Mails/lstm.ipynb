{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b19bc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be41fef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I don't have anybody's number, I still haven't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Congrats! 2 mobile 3G Videophones R yours. cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>She is our sister.. She belongs 2 our family.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ya very nice. . .be ready on thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Okie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>ham</td>\n",
       "      <td>No..jst change tat only..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey darlin.. i can pick u up at college if u t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>ham</td>\n",
       "      <td>Btw regarding that we should really try to see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>ham</td>\n",
       "      <td>Don't fret. I'll buy the ovulation test strips...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>ham</td>\n",
       "      <td>Still in the area of the restaurant. Ill try t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4458 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                              Email\n",
       "0      ham  I don't have anybody's number, I still haven't...\n",
       "1     spam  Congrats! 2 mobile 3G Videophones R yours. cal...\n",
       "2      ham  She is our sister.. She belongs 2 our family.....\n",
       "3      ham              Ya very nice. . .be ready on thursday\n",
       "4      ham                                               Okie\n",
       "...    ...                                                ...\n",
       "4453   ham                          No..jst change tat only..\n",
       "4454   ham  Hey darlin.. i can pick u up at college if u t...\n",
       "4455   ham  Btw regarding that we should really try to see...\n",
       "4456   ham  Don't fret. I'll buy the ovulation test strips...\n",
       "4457   ham  Still in the area of the restaurant. Ill try t...\n",
       "\n",
       "[4458 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'F:\\BaiduNetdiskDownload\\rb_mails\\train.csv', encoding = \"utf-8\")\n",
    "data[[\"Label\",\"Email\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c046b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除标点符号及两个以上的空格\n",
    "data['Email'] = data['Email'].apply(lambda x:re.sub('[!@#$:).;,?&]', ' ', x.lower()))\n",
    "data['Email'] = data['Email'].apply(lambda x:re.sub(' ', ' ', x))\n",
    "# 单词转换为小写\n",
    "data['Email'] = data['Email'].apply(lambda x:\" \".join(x.lower() for x in x.split()))\n",
    "# 去除停止词 ，如a、an、the、高频介词、连词、代词等\n",
    "stop = stopwords.words('english')\n",
    "data['Email'] = data['Email'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "# 分词处理，希望能够实现还原英文单词原型\n",
    "st = PorterStemmer()\n",
    "data['Email'] = data['Email'].apply(lambda x: \" \".join([word for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4aff77ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7371 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#分出训练集和测试集\n",
    "train=data[:4000]\n",
    "test=data[4000:]\n",
    "# 每个序列的最大长度，多了截断，少了补0\n",
    "max_sequence_length = 50\n",
    "#只保留频率最高的前20000个词\n",
    "num_words = 5000\n",
    "# 嵌入的维度\n",
    "embedding_dim = 100\n",
    "# 找出经常出现的单词，分词器\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(train.Email)\n",
    "train_sequences = tokenizer.texts_to_sequences(train.Email)\n",
    "test_sequences = tokenizer.texts_to_sequences(test.Email)\n",
    "\n",
    "# dictionary containing words and their index\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "# get only the top frequent words on train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27e0f518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 50)\n",
      "(458, 50)\n"
     ]
    }
   ],
   "source": [
    "train_x = pad_sequences(train_sequences, maxlen=max_sequence_length)\n",
    "# get only the top frequent words on test\n",
    "test_x = pad_sequences(test_sequences, maxlen=max_sequence_length)\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "259796c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载数据完成\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 128)               66560     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,818\n",
      "Trainable params: 66,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\hello\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 8s 78ms/step - loss: 0.3695 - accuracy: 0.8593 - val_loss: 0.2768 - val_accuracy: 0.8843\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 2s 57ms/step - loss: 0.2668 - accuracy: 0.8680 - val_loss: 0.2575 - val_accuracy: 0.8908\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 2s 56ms/step - loss: 0.2497 - accuracy: 0.8813 - val_loss: 0.2549 - val_accuracy: 0.8974\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.2418 - accuracy: 0.8830 - val_loss: 0.2544 - val_accuracy: 0.8996\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 0.2384 - accuracy: 0.8928 - val_loss: 0.2545 - val_accuracy: 0.9017\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 0.2335 - accuracy: 0.8978 - val_loss: 0.2490 - val_accuracy: 0.8974\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 0.2343 - accuracy: 0.8960 - val_loss: 0.2443 - val_accuracy: 0.8974\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.2278 - accuracy: 0.8990 - val_loss: 0.2436 - val_accuracy: 0.8996\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 0.2251 - accuracy: 0.9025 - val_loss: 0.2509 - val_accuracy: 0.8996\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 0.2215 - accuracy: 0.9053 - val_loss: 0.2490 - val_accuracy: 0.8908\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 2s 52ms/step - loss: 0.2216 - accuracy: 0.9047 - val_loss: 0.2454 - val_accuracy: 0.8974\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 0.2224 - accuracy: 0.9068 - val_loss: 0.2455 - val_accuracy: 0.8843\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.2207 - accuracy: 0.9053 - val_loss: 0.2494 - val_accuracy: 0.8974\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.2169 - accuracy: 0.9057 - val_loss: 0.2397 - val_accuracy: 0.8952\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 0.2154 - accuracy: 0.9060 - val_loss: 0.2534 - val_accuracy: 0.8930\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.2131 - accuracy: 0.9097 - val_loss: 0.2385 - val_accuracy: 0.8974\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 2s 55ms/step - loss: 0.2124 - accuracy: 0.9080 - val_loss: 0.2352 - val_accuracy: 0.8930\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.2082 - accuracy: 0.9130 - val_loss: 0.2404 - val_accuracy: 0.8908\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 2s 53ms/step - loss: 0.2105 - accuracy: 0.9150 - val_loss: 0.2382 - val_accuracy: 0.9017\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 2s 54ms/step - loss: 0.2038 - accuracy: 0.9168 - val_loss: 0.2515 - val_accuracy: 0.8908\n",
      "LSTM test score: 0.2515014410018921\n",
      "LSTM test accuracy: 0.8908296823501587\n"
     ]
    }
   ],
   "source": [
    "# 标签向量化\n",
    "# [0,1]: ham;[1,0]:spam\n",
    "def lable_vectorize(labels):\n",
    "    label_vec = np.zeros([len(labels), 2])\n",
    "    for i, label in enumerate(labels):\n",
    "        if str(label) == 'ham':\n",
    "            label_vec[i][0] = 1\n",
    "        else:\n",
    "            label_vec[i][1] = 1\n",
    "    return label_vec\n",
    "\n",
    "\n",
    "train_y = lable_vectorize(train['Label'])\n",
    "test_y = lable_vectorize(test['Label'])\n",
    "X_train = np.reshape(train_x , (train_x .shape[0], train_x .shape[1], 1))\n",
    "X_test = np.reshape(test_x, (test_x .shape[0], test_x .shape[1], 1))\n",
    "print(\"加载数据完成\")\n",
    "#=============================================================================================\n",
    "#=============================================================================================\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 20\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "n_hidden = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_hidden,\n",
    "               batch_input_shape=(None, max_sequence_length, 1),\n",
    "               unroll=True))\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "# plot_model(model, to_file='lstm.png',show_shapes='True')\n",
    "\n",
    "adam = Adam(lr=learning_rate)\n",
    "model.summary()\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=training_iters,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y))\n",
    "\n",
    "scores = model.evaluate(X_test, test_y, verbose=0)\n",
    "print('LSTM test score:', scores[0])\n",
    "print('LSTM test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84de1717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72ffc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bcd8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hello]",
   "language": "python",
   "name": "conda-env-hello-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
