{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42524baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43e5c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['many', 'picture', '.', 'time', 'much', '!']\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "text = \"their are so many picture. how are you do this time very much!\"\n",
    "clean_text = []\n",
    "for word in nltk.word_tokenize(text):\n",
    "    if word not in stop:\n",
    "        clean_text.append(word)\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aecd6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New competition launched :\n"
     ]
    }
   ],
   "source": [
    "example = \"New competition launched :https://www.kaggle.com/c/nlp-getting-started\"\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "\n",
    "\n",
    "print(remove_URL(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf176c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"\"\"<div>\n",
    "<h1>Real or Fake</h1>\n",
    "<p>Kaggle </p>\n",
    "<a href=\"https://www.kaggle.com/c/nlp-getting-started\">getting started</a>\n",
    "</div>\"\"\"\n",
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473688a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ec4587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punct(text):\n",
    "    # 对punctuation中的词进行删除\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dd15eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_email = pd.read_csv(r\"F:\\BaiduNetdiskDownload\\rb_mails\\train.csv\", usecols=[2], encoding='utf-8')\n",
    "train_label = pd.read_csv(r\"F:\\BaiduNetdiskDownload\\rb_mails\\train.csv\", usecols=[1], encoding='utf-8')\n",
    "test_email = pd.read_csv(r\"F:\\BaiduNetdiskDownload\\rb_mails\\test_noLabel.csv\", usecols=[1], encoding='utf-8')\n",
    "# test_label = pd.read_csv(r\"F:\\BaiduNetdiskDownload\\output_dtree.csv\", usecols=[1], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f46fdd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes see ya not on the dot'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = np.array(train_email).reshape((1, len(train_email)))[0].tolist()\n",
    "label_train = np.array(train_label).reshape((1, len(train_email)))[0].tolist()\n",
    "\n",
    "# data_dev = [data_train[i] for i in range(len(data_train)) if label_train[i] == \"spam\" ]\n",
    "data_dev = np.array(test_email).reshape((1, len(test_email)))[0].tolist()\n",
    "# label_dev = np.array(test_label).reshape((1, len(test_email)))[0].tolist()\n",
    "data_dev[178]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d115a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(pred,item,data_dev):\n",
    "    spam = r\"F:\\BaiduNetdiskDownload\\rb_mails\\spam_word.txt\"\n",
    "    ham = r\"F:\\BaiduNetdiskDownload\\rb_mails\\ham_word.txt\"\n",
    "    context = data_dev[item]\n",
    "    #pd.read_csv(r\"F:\\BaiduNetdiskDownload\\rb_mails\\test_noLabel.csv\", usecols=[1], encoding='utf-8')\n",
    "    p = pred\n",
    "    with open(spam, 'r') as f:\n",
    "        spam_list = [line.strip() for line in f.readlines()]\n",
    "    with open(ham, 'r') as f:\n",
    "        ham_list = [line.strip() for line in f.readlines()]\n",
    "    for string in spam_list:\n",
    "        if string in context.lower():\n",
    "            p = \"spam\"\n",
    "    for string in ham_list:\n",
    "        if string in context.lower():\n",
    "            p = \"ham\"\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc8cd55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29:Nokia phone is lovly..spam\n",
      "32:Check Out Choose Your Babe Videos @ sms.shsex.netUN fgkslpoPW fgkslpoham\n",
      "41:Mathews or tait or edwards or andersonspam\n",
      "78:Hasn't that been the pattern recently crap weekends?ham\n",
      "208:Sac needs to carry on:)ham\n",
      "266:Can... I'm free...ham\n",
      "280:Santa Calling! Would your little ones like a call from Santa Xmas eve? Call 09058094583 to book your time.spam\n",
      "360:Download as many ringtones as u like no restrictions, 1000s 2 choose. U can even send 2 yr buddys. Txt Sir to 80082 ? spam\n",
      "494:G.W.Rham\n",
      "516:ringtoneking 84484spam\n",
      "548:Ever thought about living a good life with a perfect partner? Just txt back NAME and AGE to join the mobile community. (100p/SMS)ham\n",
      "568:FROM 88066 LOST ?2 HELPspam\n",
      "651:I fetch yun or u fetch?ham\n",
      "689:You will be receiving this week's Triple Echo ringtone shortly. Enjoy it!ham\n",
      "700:Please CALL 08712402578 immediately as there is an urgent message waiting for youspam\n",
      "707:As per your request 'Maangalyam (Alaipayuthe)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertuneham\n",
      "714:Ultimately tor motive tui achieve korli.ham\n",
      "751:Please CALL 08712402972 immediately as there is an urgent message waiting for youspam\n",
      "753:Total video converter free download type this in google search:)spam\n",
      "786:I'm freezing and craving ice. Fmlham\n",
      "814:Have you heard from this week?ham\n",
      "834:Wow v v impressed. Have funs shopping!ham\n",
      "914:Which channel:-):-):):-).ham\n",
      "998:staff.science.nus.edu.sg/~phyhcmk/teaching/pc1323ham\n",
      "1044:K:)eng rocking in ashes:)ham\n",
      "1051:K..k.:)congratulation ..ham\n",
      "1078:Audrie lousy autocorrectham\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# 使用词袋模型\n",
    "vectorizer = CountVectorizer()\n",
    "# CountVectorizer类会把文本全部转换为小写，然后将文本词块化。主要是分词，分标点\n",
    "data_train_cnt = vectorizer.fit_transform(data_train)\n",
    "data_test_cnt = vectorizer.transform(data_dev)\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(data_train_cnt, label_train)\n",
    "# score = clf.score(data_test_cnt, label_dev)\n",
    "k = clf.predict(data_test_cnt)\n",
    "k_rate = clf.predict_proba(data_test_cnt)\n",
    "cnt = 0\n",
    "for item,pred in enumerate(k):\n",
    "    # p = decision_tree(pred,item,data_dev)\n",
    "    p = pred\n",
    "    # test_label.loc[item] = p\n",
    "    if k_rate[item][0]<0.9 and k_rate[item][0]>0.1:\n",
    "        print(str(item+2) + \":\" +data_dev[item] + p)\n",
    "        cnt += 1\n",
    "    # print(str(item) + \":\" + p)\n",
    "# test_label.to_csv(r'F:\\BaiduNetdiskDownload\\rb_mails\\mlp\\out.csv',index=False)\n",
    "print(cnt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "288394b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74727792 0.25272208]\n"
     ]
    }
   ],
   "source": [
    "predt = clf.predict_proba(data_test_cnt)\n",
    "print(predt[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c6f48dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ok.ok ok..then..whats ur todays plan'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dev[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0d570c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam = r\"F:\\BaiduNetdiskDownload\\rb_mails\\spam_word.txt\"\n",
    "ham = r\"F:\\BaiduNetdiskDownload\\rb_mails\\ham_word.txt\"\n",
    "context = \"Hi babe its Chloe, how r u? I was smashed on saturday night, it was great! How was your weekend? U been missing me? SP visionsms.com Text stop to stop 150p/text\"\n",
    "pred = \"first\"\n",
    "with open(spam, 'r') as f:\n",
    "    spam_list = [line.strip() for line in f.readlines()]\n",
    "with open(ham, 'r') as f:\n",
    "    ham_list = [line.strip() for line in f.readlines()]\n",
    "for string in spam_list:\n",
    "    if string in context.lower():\n",
    "        pred = \"spam\"\n",
    "for string in ham_list:\n",
    "    if string in context.lower():\n",
    "        pred = \"ham\"\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aadb6c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fullonsms.com']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8131e8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32523d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PyTorch] *",
   "language": "python",
   "name": "conda-env-PyTorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
