2023-06-29 17:41:32 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:36 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:36 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:36 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:36 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:36 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:19770
2023-06-29 17:41:36 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:19770
2023-06-29 17:41:36 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:19770
2023-06-29 17:41:36 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:19770
2023-06-29 17:41:36 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-06-29 17:41:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-06-29 17:41:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-06-29 17:41:37 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-06-29 17:41:37 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-06-29 17:41:37 | INFO | fairseq.distributed.utils | initialized host autodl-container-48f511a7e8-06cfee94 as rank 0
2023-06-29 17:41:37 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-06-29 17:41:37 | INFO | fairseq.distributed.utils | initialized host autodl-container-48f511a7e8-06cfee94 as rank 3
2023-06-29 17:41:37 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-06-29 17:41:37 | INFO | fairseq.distributed.utils | initialized host autodl-container-48f511a7e8-06cfee94 as rank 1
2023-06-29 17:41:37 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-06-29 17:41:37 | INFO | fairseq.distributed.utils | initialized host autodl-container-48f511a7e8-06cfee94 as rank 2
2023-06-29 17:41:39 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'logs/', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:19770', 'distributed_port': 19770, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 8, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 200000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.001], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 10, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='/root/autodl-tmp/NLP_hw3/nmt/data/TED/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', debug_param_names=False, decoder_attention_heads=8, decoder_embed_dim=512, decoder_embed_path=None, decoder_ffn_embed_dim=2048, decoder_input_dim=512, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=512, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=4, distributed_port=-1, distributed_rank=0, distributed_world_size=4, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=8, encoder_embed_dim=512, encoder_embed_path=None, encoder_ffn_embed_dim=2048, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=10, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.001], lr_scheduler='inverse_sqrt', max_epoch=0, max_tokens=4096, max_tokens_valid=4096, max_update=200000, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_src_tgt_embed=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=True, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=4, num_batch_buckets=0, num_shards=1, num_workers=8, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='/root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=False, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang='en', stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang='zh', task='translation', tensorboard_logdir='logs/', threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=1e-07, warmup_updates=4000, weight_decay=0.0, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': '/root/autodl-tmp/NLP_hw3/nmt/data/TED/data-bin', 'source_lang': 'en', 'target_lang': 'zh', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.001]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.001]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-06-29 17:41:39 | INFO | fairseq.tasks.translation | [en] dictionary: 31280 types
2023-06-29 17:41:39 | INFO | fairseq.tasks.translation | [zh] dictionary: 38888 types
2023-06-29 17:41:41 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(31280, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(38888, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=512, out_features=38888, bias=False)
  )
)
2023-06-29 17:41:41 | INFO | fairseq_cli.train | task: TranslationTask
2023-06-29 17:41:41 | INFO | fairseq_cli.train | model: TransformerModel
2023-06-29 17:41:41 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2023-06-29 17:41:41 | INFO | fairseq_cli.train | num. shared model params: 99,975,168 (num. trained: 99,975,168)
2023-06-29 17:41:41 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-06-29 17:41:41 | INFO | fairseq.data.data_utils | loaded 9,957 examples from: /root/autodl-tmp/NLP_hw3/nmt/data/TED/data-bin/valid.en-zh.en
2023-06-29 17:41:41 | INFO | fairseq.data.data_utils | loaded 9,957 examples from: /root/autodl-tmp/NLP_hw3/nmt/data/TED/data-bin/valid.en-zh.zh
2023-06-29 17:41:41 | INFO | fairseq.tasks.translation | /root/autodl-tmp/NLP_hw3/nmt/data/TED/data-bin valid en-zh 9957 examples
2023-06-29 17:41:41 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-06-29 17:41:41 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
2023-06-29 17:41:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-06-29 17:41:41 | INFO | fairseq.utils | rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-06-29 17:41:41 | INFO | fairseq.utils | rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-06-29 17:41:41 | INFO | fairseq.utils | rank   2: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-06-29 17:41:41 | INFO | fairseq.utils | rank   3: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2023-06-29 17:41:41 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-06-29 17:41:41 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2023-06-29 17:41:41 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None
2023-06-29 17:41:41 | INFO | fairseq.trainer | Preparing to load checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint_last.pt
2023-06-29 17:41:41 | INFO | fairseq.trainer | No existing checkpoint found /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint_last.pt
2023-06-29 17:41:41 | INFO | fairseq.trainer | loading train data for epoch 1
2023-06-29 17:41:41 | INFO | fairseq.data.data_utils | loaded 379,083 examples from: /root/autodl-tmp/NLP_hw3/nmt/data/TED/data-bin/train.en-zh.en
2023-06-29 17:41:41 | INFO | fairseq.data.data_utils | loaded 379,083 examples from: /root/autodl-tmp/NLP_hw3/nmt/data/TED/data-bin/train.en-zh.zh
2023-06-29 17:41:41 | INFO | fairseq.tasks.translation | /root/autodl-tmp/NLP_hw3/nmt/data/TED/data-bin train en-zh 379083 examples
2023-06-29 17:41:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:41:41 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2023-06-29 17:41:41 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2023-06-29 17:41:41 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
2023-06-29 17:41:41 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2023-06-29 17:41:41 | INFO | fairseq_cli.train | begin dry-run validation on "valid" subset
2023-06-29 17:41:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:41:41 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2023-06-29 17:41:41 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2023-06-29 17:41:41 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
2023-06-29 17:41:43 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:43 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:43 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:43 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:45 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:45 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:45 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:45 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:47 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:47 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:47 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:47 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:49 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:49 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:49 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:49 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:52 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:52 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:52 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:52 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:54 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:54 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:54 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:54 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:56 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:56 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:56 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:56 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:58 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:58 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:58 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:58 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:41:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:41:58 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:41:58 | INFO | fairseq.trainer | begin training epoch 1
2023-06-29 17:41:58 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:42:00 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:00 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:00 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:00 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:02 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:02 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:02 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:02 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:04 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:04 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:04 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:05 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:07 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:07 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:07 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:07 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:09 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:09 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:09 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:09 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:11 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:13 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:13 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:13 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:13 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:16 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:16 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX
2023-06-29 17:42:17 | INFO | torch.nn.parallel.distributed | Reducer buckets have been rebuilt in this iteration.
2023-06-29 17:42:36 | INFO | train_inner | epoch 001:    100 / 556 loss=13.829, nll_loss=13.581, ppl=12252.4, wps=71593.6, ups=5.27, wpb=13586, bsz=669.8, num_updates=100, lr=2.50975e-05, gnorm=2.823, train_wall=20, gb_free=19.3, wall=55
2023-06-29 17:42:55 | INFO | train_inner | epoch 001:    200 / 556 loss=11.756, nll_loss=11.264, ppl=2458.74, wps=73133.6, ups=5.35, wpb=13661, bsz=692.1, num_updates=200, lr=5.0095e-05, gnorm=1.581, train_wall=18, gb_free=19.3, wall=74
2023-06-29 17:43:13 | INFO | train_inner | epoch 001:    300 / 556 loss=10.64, nll_loss=9.946, ppl=986.49, wps=73177.9, ups=5.37, wpb=13627.1, bsz=675.2, num_updates=300, lr=7.50925e-05, gnorm=1.49, train_wall=18, gb_free=19.6, wall=93
2023-06-29 17:43:32 | INFO | train_inner | epoch 001:    400 / 556 loss=10.295, nll_loss=9.513, ppl=730.46, wps=71974.6, ups=5.37, wpb=13411.6, bsz=685.9, num_updates=400, lr=0.00010009, gnorm=1.441, train_wall=18, gb_free=19.3, wall=111
2023-06-29 17:43:51 | INFO | train_inner | epoch 001:    500 / 556 loss=10.041, nll_loss=9.215, ppl=594.47, wps=72817.2, ups=5.37, wpb=13555.2, bsz=694.6, num_updates=500, lr=0.000125087, gnorm=1.395, train_wall=18, gb_free=18.9, wall=130
2023-06-29 17:44:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 17:44:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:44:01 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:44:02 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 9.71 | nll_loss 8.782 | ppl 440.21 | wps 213209 | wpb 9430 | bsz 473.9 | num_updates 556
2023-06-29 17:44:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 556 updates
2023-06-29 17:44:02 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint1.pt
2023-06-29 17:44:04 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint1.pt
2023-06-29 17:44:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint1.pt (epoch 1 @ 556 updates, score 9.71) (writing took 2.8904604353010654 seconds)
2023-06-29 17:44:05 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-06-29 17:44:05 | INFO | train | epoch 001 | loss 11.173 | nll_loss 10.541 | ppl 1489.59 | wps 69868.5 | ups 5.15 | wpb 13556 | bsz 681.8 | num_updates 556 | lr 0.000139086 | gnorm 1.711 | train_wall 104 | gb_free 19.6 | wall 144
2023-06-29 17:44:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:44:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:44:05 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:44:05 | INFO | fairseq.trainer | begin training epoch 2
2023-06-29 17:44:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:44:13 | INFO | train_inner | epoch 002:     44 / 556 loss=9.849, nll_loss=8.994, ppl=509.75, wps=58925.3, ups=4.42, wpb=13332.4, bsz=654.7, num_updates=600, lr=0.000150085, gnorm=1.351, train_wall=18, gb_free=19.1, wall=152
2023-06-29 17:44:32 | INFO | train_inner | epoch 002:    144 / 556 loss=9.574, nll_loss=8.68, ppl=410.21, wps=71798.3, ups=5.36, wpb=13405.4, bsz=711.9, num_updates=700, lr=0.000175082, gnorm=1.304, train_wall=18, gb_free=19.4, wall=171
2023-06-29 17:44:50 | INFO | train_inner | epoch 002:    244 / 556 loss=9.394, nll_loss=8.474, ppl=355.49, wps=73483.2, ups=5.38, wpb=13651.7, bsz=675.4, num_updates=800, lr=0.00020008, gnorm=1.177, train_wall=18, gb_free=19, wall=190
2023-06-29 17:45:09 | INFO | train_inner | epoch 002:    344 / 556 loss=9.239, nll_loss=8.295, ppl=314.05, wps=73671.8, ups=5.4, wpb=13650.3, bsz=692.2, num_updates=900, lr=0.000225077, gnorm=1.246, train_wall=18, gb_free=19.1, wall=208
2023-06-29 17:45:28 | INFO | train_inner | epoch 002:    444 / 556 loss=9.092, nll_loss=8.127, ppl=279.5, wps=72965, ups=5.33, wpb=13687.8, bsz=671.3, num_updates=1000, lr=0.000250075, gnorm=1.129, train_wall=19, gb_free=19.1, wall=227
2023-06-29 17:45:47 | INFO | train_inner | epoch 002:    544 / 556 loss=8.964, nll_loss=7.979, ppl=252.24, wps=71969.8, ups=5.34, wpb=13473.5, bsz=686.3, num_updates=1100, lr=0.000275072, gnorm=1.139, train_wall=18, gb_free=19.1, wall=246
2023-06-29 17:45:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 17:45:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:45:49 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:45:50 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 8.672 | nll_loss 7.601 | ppl 194.21 | wps 215346 | wpb 9430 | bsz 473.9 | num_updates 1112 | best_loss 8.672
2023-06-29 17:45:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 1112 updates
2023-06-29 17:45:50 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint2.pt
2023-06-29 17:45:51 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint2.pt
2023-06-29 17:45:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint2.pt (epoch 2 @ 1112 updates, score 8.672) (writing took 3.7009861916303635 seconds)
2023-06-29 17:45:53 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-06-29 17:45:53 | INFO | train | epoch 002 | loss 9.287 | nll_loss 8.35 | ppl 326.38 | wps 69480.5 | ups 5.13 | wpb 13556 | bsz 681.8 | num_updates 1112 | lr 0.000278072 | gnorm 1.2 | train_wall 102 | gb_free 18.9 | wall 253
2023-06-29 17:45:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:45:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:45:54 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:45:54 | INFO | fairseq.trainer | begin training epoch 3
2023-06-29 17:45:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:46:10 | INFO | train_inner | epoch 003:     88 / 556 loss=8.778, nll_loss=7.766, ppl=217.74, wps=57032.8, ups=4.24, wpb=13439, bsz=665.6, num_updates=1200, lr=0.00030007, gnorm=1.004, train_wall=18, gb_free=19.1, wall=269
2023-06-29 17:46:29 | INFO | train_inner | epoch 003:    188 / 556 loss=8.609, nll_loss=7.57, ppl=190.05, wps=72650.4, ups=5.33, wpb=13631, bsz=669.2, num_updates=1300, lr=0.000325067, gnorm=1.013, train_wall=19, gb_free=19.1, wall=288
2023-06-29 17:46:48 | INFO | train_inner | epoch 003:    288 / 556 loss=8.437, nll_loss=7.372, ppl=165.67, wps=72896.2, ups=5.34, wpb=13649.8, bsz=701.8, num_updates=1400, lr=0.000350065, gnorm=0.981, train_wall=18, gb_free=19.9, wall=307
2023-06-29 17:47:06 | INFO | train_inner | epoch 003:    388 / 556 loss=8.326, nll_loss=7.244, ppl=151.62, wps=72864.2, ups=5.35, wpb=13610.1, bsz=669, num_updates=1500, lr=0.000375062, gnorm=0.997, train_wall=18, gb_free=18.9, wall=325
2023-06-29 17:47:25 | INFO | train_inner | epoch 003:    488 / 556 loss=8.152, nll_loss=7.044, ppl=131.96, wps=72554.3, ups=5.37, wpb=13523, bsz=724.5, num_updates=1600, lr=0.00040006, gnorm=0.999, train_wall=18, gb_free=18.9, wall=344
2023-06-29 17:47:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 17:47:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:47:38 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:47:39 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 7.763 | nll_loss 6.542 | ppl 93.21 | wps 215016 | wpb 9430 | bsz 473.9 | num_updates 1668 | best_loss 7.763
2023-06-29 17:47:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 1668 updates
2023-06-29 17:47:39 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint3.pt
2023-06-29 17:47:40 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint3.pt
2023-06-29 17:47:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint3.pt (epoch 3 @ 1668 updates, score 7.763) (writing took 3.6685044541954994 seconds)
2023-06-29 17:47:42 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-06-29 17:47:42 | INFO | train | epoch 003 | loss 8.408 | nll_loss 7.338 | ppl 161.83 | wps 69309.1 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 1668 | lr 0.000417058 | gnorm 0.995 | train_wall 103 | gb_free 19.4 | wall 361
2023-06-29 17:47:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:47:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:47:42 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:47:42 | INFO | fairseq.trainer | begin training epoch 4
2023-06-29 17:47:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:47:48 | INFO | train_inner | epoch 004:     32 / 556 loss=8.058, nll_loss=6.935, ppl=122.39, wps=57696.4, ups=4.27, wpb=13507.2, bsz=646.6, num_updates=1700, lr=0.000425057, gnorm=0.958, train_wall=18, gb_free=19.4, wall=367
2023-06-29 17:48:07 | INFO | train_inner | epoch 004:    132 / 556 loss=7.798, nll_loss=6.637, ppl=99.52, wps=72603.2, ups=5.32, wpb=13642.9, bsz=687.2, num_updates=1800, lr=0.000450055, gnorm=0.905, train_wall=19, gb_free=19.1, wall=386
2023-06-29 17:48:26 | INFO | train_inner | epoch 004:    232 / 556 loss=7.76, nll_loss=6.59, ppl=96.31, wps=71822.3, ups=5.35, wpb=13426.8, bsz=646.3, num_updates=1900, lr=0.000475052, gnorm=0.932, train_wall=18, gb_free=19.4, wall=405
2023-06-29 17:48:45 | INFO | train_inner | epoch 004:    332 / 556 loss=7.597, nll_loss=6.403, ppl=84.6, wps=72742.6, ups=5.31, wpb=13701.4, bsz=685.2, num_updates=2000, lr=0.00050005, gnorm=0.938, train_wall=19, gb_free=19.3, wall=424
2023-06-29 17:49:03 | INFO | train_inner | epoch 004:    432 / 556 loss=7.513, nll_loss=6.304, ppl=79.02, wps=72566.8, ups=5.36, wpb=13532.6, bsz=667.5, num_updates=2100, lr=0.000525047, gnorm=0.893, train_wall=18, gb_free=19.1, wall=442
2023-06-29 17:49:22 | INFO | train_inner | epoch 004:    532 / 556 loss=7.379, nll_loss=6.15, ppl=71, wps=72139.6, ups=5.35, wpb=13473.8, bsz=702.4, num_updates=2200, lr=0.000550045, gnorm=0.876, train_wall=18, gb_free=19.2, wall=461
2023-06-29 17:49:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 17:49:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:49:26 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:49:27 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 7.097 | nll_loss 5.746 | ppl 53.68 | wps 216930 | wpb 9430 | bsz 473.9 | num_updates 2224 | best_loss 7.097
2023-06-29 17:49:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 2224 updates
2023-06-29 17:49:27 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint4.pt
2023-06-29 17:49:29 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint4.pt
2023-06-29 17:49:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint4.pt (epoch 4 @ 2224 updates, score 7.097) (writing took 3.6975260451436043 seconds)
2023-06-29 17:49:31 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-06-29 17:49:31 | INFO | train | epoch 004 | loss 7.611 | nll_loss 6.419 | ppl 85.58 | wps 69199.2 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 2224 | lr 0.000556044 | gnorm 0.909 | train_wall 103 | gb_free 19.1 | wall 470
2023-06-29 17:49:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:49:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:49:31 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:49:31 | INFO | fairseq.trainer | begin training epoch 5
2023-06-29 17:49:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:49:45 | INFO | train_inner | epoch 005:     76 / 556 loss=7.235, nll_loss=5.985, ppl=63.34, wps=57376.4, ups=4.26, wpb=13455.5, bsz=665.7, num_updates=2300, lr=0.000575042, gnorm=0.875, train_wall=18, gb_free=19.1, wall=485
2023-06-29 17:50:04 | INFO | train_inner | epoch 005:    176 / 556 loss=7.081, nll_loss=5.805, ppl=55.92, wps=73013.5, ups=5.34, wpb=13667.9, bsz=671.1, num_updates=2400, lr=0.00060004, gnorm=0.843, train_wall=18, gb_free=19.8, wall=503
2023-06-29 17:50:23 | INFO | train_inner | epoch 005:    276 / 556 loss=6.979, nll_loss=5.687, ppl=51.5, wps=72477.9, ups=5.35, wpb=13552.9, bsz=706.8, num_updates=2500, lr=0.000625037, gnorm=0.839, train_wall=18, gb_free=18.8, wall=522
2023-06-29 17:50:42 | INFO | train_inner | epoch 005:    376 / 556 loss=6.901, nll_loss=5.595, ppl=48.33, wps=72616.2, ups=5.32, wpb=13652.8, bsz=694.1, num_updates=2600, lr=0.000650035, gnorm=0.824, train_wall=19, gb_free=18.9, wall=541
2023-06-29 17:51:00 | INFO | train_inner | epoch 005:    476 / 556 loss=6.793, nll_loss=5.471, ppl=44.35, wps=73444.6, ups=5.37, wpb=13674.2, bsz=709.6, num_updates=2700, lr=0.000675032, gnorm=0.774, train_wall=18, gb_free=19.1, wall=559
2023-06-29 17:51:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 17:51:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:51:15 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:51:16 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.57 | nll_loss 5.123 | ppl 34.84 | wps 216701 | wpb 9430 | bsz 473.9 | num_updates 2780 | best_loss 6.57
2023-06-29 17:51:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 2780 updates
2023-06-29 17:51:16 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint5.pt
2023-06-29 17:51:18 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint5.pt
2023-06-29 17:51:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint5.pt (epoch 5 @ 2780 updates, score 6.57) (writing took 3.776313226670027 seconds)
2023-06-29 17:51:20 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-06-29 17:51:20 | INFO | train | epoch 005 | loss 6.96 | nll_loss 5.665 | ppl 50.72 | wps 69287.7 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 2780 | lr 0.00069503 | gnorm 0.833 | train_wall 102 | gb_free 19.3 | wall 579
2023-06-29 17:51:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:51:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:51:20 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:51:20 | INFO | fairseq.trainer | begin training epoch 6
2023-06-29 17:51:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:51:24 | INFO | train_inner | epoch 006:     20 / 556 loss=6.744, nll_loss=5.413, ppl=42.61, wps=57221.3, ups=4.26, wpb=13430.2, bsz=680.5, num_updates=2800, lr=0.00070003, gnorm=0.833, train_wall=18, gb_free=19, wall=583
2023-06-29 17:51:42 | INFO | train_inner | epoch 006:    120 / 556 loss=6.523, nll_loss=5.161, ppl=35.77, wps=72763.4, ups=5.36, wpb=13576.3, bsz=666.6, num_updates=2900, lr=0.000725027, gnorm=0.775, train_wall=18, gb_free=19.7, wall=602
2023-06-29 17:52:01 | INFO | train_inner | epoch 006:    220 / 556 loss=6.468, nll_loss=5.094, ppl=34.15, wps=73224.5, ups=5.36, wpb=13662.4, bsz=712.9, num_updates=3000, lr=0.000750025, gnorm=0.795, train_wall=18, gb_free=19.5, wall=620
2023-06-29 17:52:20 | INFO | train_inner | epoch 006:    320 / 556 loss=6.504, nll_loss=5.132, ppl=35.08, wps=71773.9, ups=5.34, wpb=13435.2, bsz=670.8, num_updates=3100, lr=0.000775022, gnorm=0.808, train_wall=18, gb_free=19.3, wall=639
2023-06-29 17:52:38 | INFO | train_inner | epoch 006:    420 / 556 loss=6.443, nll_loss=5.063, ppl=33.42, wps=72816.2, ups=5.35, wpb=13602, bsz=652.8, num_updates=3200, lr=0.00080002, gnorm=0.77, train_wall=18, gb_free=18.9, wall=658
2023-06-29 17:52:57 | INFO | train_inner | epoch 006:    520 / 556 loss=6.408, nll_loss=5.023, ppl=32.52, wps=71761.2, ups=5.34, wpb=13445, bsz=687, num_updates=3300, lr=0.000825017, gnorm=0.775, train_wall=18, gb_free=18.9, wall=676
2023-06-29 17:53:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 17:53:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:53:04 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:53:05 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 6.231 | nll_loss 4.739 | ppl 26.71 | wps 216392 | wpb 9430 | bsz 473.9 | num_updates 3336 | best_loss 6.231
2023-06-29 17:53:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 3336 updates
2023-06-29 17:53:05 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint6.pt
2023-06-29 17:53:06 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint6.pt
2023-06-29 17:53:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint6.pt (epoch 6 @ 3336 updates, score 6.231) (writing took 3.6592549718916416 seconds)
2023-06-29 17:53:08 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-06-29 17:53:08 | INFO | train | epoch 006 | loss 6.463 | nll_loss 5.088 | ppl 34.01 | wps 69401 | ups 5.12 | wpb 13556 | bsz 681.8 | num_updates 3336 | lr 0.000834017 | gnorm 0.784 | train_wall 102 | gb_free 19 | wall 688
2023-06-29 17:53:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:53:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:53:09 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:53:09 | INFO | fairseq.trainer | begin training epoch 7
2023-06-29 17:53:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:53:20 | INFO | train_inner | epoch 007:     64 / 556 loss=6.236, nll_loss=4.827, ppl=28.39, wps=58328.5, ups=4.29, wpb=13598.1, bsz=671.4, num_updates=3400, lr=0.000850015, gnorm=0.767, train_wall=18, gb_free=19.1, wall=700
2023-06-29 17:53:39 | INFO | train_inner | epoch 007:    164 / 556 loss=6.133, nll_loss=4.707, ppl=26.11, wps=72883.9, ups=5.36, wpb=13594.7, bsz=701.8, num_updates=3500, lr=0.000875012, gnorm=0.764, train_wall=18, gb_free=19.1, wall=718
2023-06-29 17:53:58 | INFO | train_inner | epoch 007:    264 / 556 loss=6.209, nll_loss=4.791, ppl=27.68, wps=71682.2, ups=5.35, wpb=13408.8, bsz=653.1, num_updates=3600, lr=0.00090001, gnorm=0.802, train_wall=18, gb_free=19.8, wall=737
2023-06-29 17:54:17 | INFO | train_inner | epoch 007:    364 / 556 loss=6.124, nll_loss=4.695, ppl=25.91, wps=72676.5, ups=5.34, wpb=13609.3, bsz=702.6, num_updates=3700, lr=0.000925007, gnorm=0.748, train_wall=18, gb_free=19.3, wall=756
2023-06-29 17:54:35 | INFO | train_inner | epoch 007:    464 / 556 loss=6.154, nll_loss=4.73, ppl=26.54, wps=72024.1, ups=5.37, wpb=13402, bsz=696.9, num_updates=3800, lr=0.000950005, gnorm=0.782, train_wall=18, gb_free=19, wall=774
2023-06-29 17:54:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 17:54:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:54:52 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:54:53 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 6.028 | nll_loss 4.497 | ppl 22.58 | wps 215949 | wpb 9430 | bsz 473.9 | num_updates 3892 | best_loss 6.028
2023-06-29 17:54:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 3892 updates
2023-06-29 17:54:53 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint7.pt
2023-06-29 17:54:55 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint7.pt
2023-06-29 17:54:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint7.pt (epoch 7 @ 3892 updates, score 6.028) (writing took 3.715842127799988 seconds)
2023-06-29 17:54:57 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-06-29 17:54:57 | INFO | train | epoch 007 | loss 6.151 | nll_loss 4.727 | ppl 26.48 | wps 69374.2 | ups 5.12 | wpb 13556 | bsz 681.8 | num_updates 3892 | lr 0.000973003 | gnorm 0.767 | train_wall 102 | gb_free 18.8 | wall 796
2023-06-29 17:54:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:54:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:54:57 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:54:57 | INFO | fairseq.trainer | begin training epoch 8
2023-06-29 17:54:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:54:59 | INFO | train_inner | epoch 008:      8 / 556 loss=6.109, nll_loss=4.68, ppl=25.63, wps=58299.8, ups=4.23, wpb=13779.3, bsz=668, num_updates=3900, lr=0.000975002, gnorm=0.748, train_wall=19, gb_free=18.8, wall=798
2023-06-29 17:55:17 | INFO | train_inner | epoch 008:    108 / 556 loss=5.883, nll_loss=4.419, ppl=21.39, wps=72154.9, ups=5.35, wpb=13480.8, bsz=679.2, num_updates=4000, lr=0.001, gnorm=0.759, train_wall=18, gb_free=19, wall=817
2023-06-29 17:55:36 | INFO | train_inner | epoch 008:    208 / 556 loss=5.931, nll_loss=4.473, ppl=22.2, wps=72791.1, ups=5.36, wpb=13575.9, bsz=714.6, num_updates=4100, lr=0.00098773, gnorm=0.798, train_wall=18, gb_free=19, wall=835
2023-06-29 17:55:55 | INFO | train_inner | epoch 008:    308 / 556 loss=6, nll_loss=4.55, ppl=23.43, wps=72279.8, ups=5.36, wpb=13496.1, bsz=641.8, num_updates=4200, lr=0.0009759, gnorm=0.803, train_wall=18, gb_free=19, wall=854
2023-06-29 17:56:14 | INFO | train_inner | epoch 008:    408 / 556 loss=5.91, nll_loss=4.45, ppl=21.86, wps=72604.8, ups=5.34, wpb=13608.5, bsz=702.3, num_updates=4300, lr=0.000964486, gnorm=0.753, train_wall=18, gb_free=18.9, wall=873
2023-06-29 17:56:32 | INFO | train_inner | epoch 008:    508 / 556 loss=5.91, nll_loss=4.451, ppl=21.88, wps=73257.9, ups=5.34, wpb=13707.2, bsz=681, num_updates=4400, lr=0.000953463, gnorm=0.731, train_wall=18, gb_free=19.1, wall=891
2023-06-29 17:56:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 17:56:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:56:41 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:56:42 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.892 | nll_loss 4.335 | ppl 20.19 | wps 213963 | wpb 9430 | bsz 473.9 | num_updates 4448 | best_loss 5.892
2023-06-29 17:56:42 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 4448 updates
2023-06-29 17:56:42 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint8.pt
2023-06-29 17:56:44 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint8.pt
2023-06-29 17:56:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint8.pt (epoch 8 @ 4448 updates, score 5.892) (writing took 3.8185968436300755 seconds)
2023-06-29 17:56:46 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-06-29 17:56:46 | INFO | train | epoch 008 | loss 5.929 | nll_loss 4.471 | ppl 22.18 | wps 69246.7 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 4448 | lr 0.000948304 | gnorm 0.768 | train_wall 103 | gb_free 19.3 | wall 905
2023-06-29 17:56:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:56:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:56:46 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:56:46 | INFO | fairseq.trainer | begin training epoch 9
2023-06-29 17:56:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:56:56 | INFO | train_inner | epoch 009:     52 / 556 loss=5.791, nll_loss=4.316, ppl=19.92, wps=56298.8, ups=4.25, wpb=13235.1, bsz=697.6, num_updates=4500, lr=0.000942809, gnorm=0.788, train_wall=18, gb_free=19.2, wall=915
2023-06-29 17:57:15 | INFO | train_inner | epoch 009:    152 / 556 loss=5.676, nll_loss=4.18, ppl=18.13, wps=72152.5, ups=5.31, wpb=13578.1, bsz=676.8, num_updates=4600, lr=0.000932505, gnorm=0.731, train_wall=19, gb_free=19.1, wall=934
2023-06-29 17:57:33 | INFO | train_inner | epoch 009:    252 / 556 loss=5.701, nll_loss=4.209, ppl=18.49, wps=73600.5, ups=5.35, wpb=13765.1, bsz=657.1, num_updates=4700, lr=0.000922531, gnorm=0.745, train_wall=18, gb_free=18.9, wall=952
2023-06-29 17:57:52 | INFO | train_inner | epoch 009:    352 / 556 loss=5.72, nll_loss=4.232, ppl=18.79, wps=72276, ups=5.37, wpb=13465.2, bsz=681, num_updates=4800, lr=0.000912871, gnorm=0.738, train_wall=18, gb_free=19.4, wall=971
2023-06-29 17:58:11 | INFO | train_inner | epoch 009:    452 / 556 loss=5.726, nll_loss=4.24, ppl=18.9, wps=72700.6, ups=5.36, wpb=13566.7, bsz=665.4, num_updates=4900, lr=0.000903508, gnorm=0.728, train_wall=18, gb_free=19, wall=990
2023-06-29 17:58:29 | INFO | train_inner | epoch 009:    552 / 556 loss=5.709, nll_loss=4.224, ppl=18.68, wps=72508, ups=5.34, wpb=13584.7, bsz=706.8, num_updates=5000, lr=0.000894427, gnorm=0.757, train_wall=18, gb_free=19.7, wall=1008
2023-06-29 17:58:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 17:58:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:58:30 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:58:31 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.782 | nll_loss 4.21 | ppl 18.51 | wps 215198 | wpb 9430 | bsz 473.9 | num_updates 5004 | best_loss 5.782
2023-06-29 17:58:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 5004 updates
2023-06-29 17:58:31 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint9.pt
2023-06-29 17:58:33 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint9.pt
2023-06-29 17:58:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint9.pt (epoch 9 @ 5004 updates, score 5.782) (writing took 3.775064345449209 seconds)
2023-06-29 17:58:35 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-06-29 17:58:35 | INFO | train | epoch 009 | loss 5.699 | nll_loss 4.209 | ppl 18.49 | wps 69242 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 5004 | lr 0.00089407 | gnorm 0.746 | train_wall 103 | gb_free 19.3 | wall 1014
2023-06-29 17:58:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 17:58:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 17:58:35 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 17:58:35 | INFO | fairseq.trainer | begin training epoch 10
2023-06-29 17:58:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 17:58:53 | INFO | train_inner | epoch 010:     96 / 556 loss=5.456, nll_loss=3.931, ppl=15.25, wps=57911.1, ups=4.24, wpb=13645.3, bsz=687, num_updates=5100, lr=0.000885615, gnorm=0.704, train_wall=18, gb_free=19.1, wall=1032
2023-06-29 17:59:12 | INFO | train_inner | epoch 010:    196 / 556 loss=5.494, nll_loss=3.973, ppl=15.7, wps=72189.4, ups=5.31, wpb=13601.1, bsz=679.3, num_updates=5200, lr=0.000877058, gnorm=0.719, train_wall=19, gb_free=19.2, wall=1051
2023-06-29 17:59:31 | INFO | train_inner | epoch 010:    296 / 556 loss=5.524, nll_loss=4.007, ppl=16.08, wps=72717.3, ups=5.3, wpb=13708.2, bsz=671.5, num_updates=5300, lr=0.000868744, gnorm=0.703, train_wall=19, gb_free=19.3, wall=1070
2023-06-29 17:59:49 | INFO | train_inner | epoch 010:    396 / 556 loss=5.52, nll_loss=4.005, ppl=16.05, wps=72551.3, ups=5.36, wpb=13527.3, bsz=684, num_updates=5400, lr=0.000860663, gnorm=0.716, train_wall=18, gb_free=19.3, wall=1088
2023-06-29 18:00:08 | INFO | train_inner | epoch 010:    496 / 556 loss=5.553, nll_loss=4.043, ppl=16.48, wps=71784.1, ups=5.33, wpb=13478.4, bsz=683.5, num_updates=5500, lr=0.000852803, gnorm=0.699, train_wall=19, gb_free=19.6, wall=1107
2023-06-29 18:00:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:00:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:00:19 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:00:20 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.697 | nll_loss 4.107 | ppl 17.23 | wps 216484 | wpb 9430 | bsz 473.9 | num_updates 5560 | best_loss 5.697
2023-06-29 18:00:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 5560 updates
2023-06-29 18:00:20 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint10.pt
2023-06-29 18:00:22 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint10.pt
2023-06-29 18:00:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint10.pt (epoch 10 @ 5560 updates, score 5.697) (writing took 3.7355974838137627 seconds)
2023-06-29 18:00:24 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-06-29 18:00:24 | INFO | train | epoch 010 | loss 5.514 | nll_loss 3.997 | ppl 15.97 | wps 69096.9 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 5560 | lr 0.000848189 | gnorm 0.709 | train_wall 103 | gb_free 19.5 | wall 1123
2023-06-29 18:00:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:00:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:00:24 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:00:24 | INFO | fairseq.trainer | begin training epoch 11
2023-06-29 18:00:24 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:00:31 | INFO | train_inner | epoch 011:     40 / 556 loss=5.424, nll_loss=3.896, ppl=14.89, wps=57381.6, ups=4.25, wpb=13491, bsz=693.4, num_updates=5600, lr=0.000845154, gnorm=0.713, train_wall=18, gb_free=19, wall=1131
2023-06-29 18:00:50 | INFO | train_inner | epoch 011:    140 / 556 loss=5.298, nll_loss=3.748, ppl=13.44, wps=73664.9, ups=5.35, wpb=13768.4, bsz=708.4, num_updates=5700, lr=0.000837708, gnorm=0.705, train_wall=18, gb_free=19, wall=1149
2023-06-29 18:01:09 | INFO | train_inner | epoch 011:    240 / 556 loss=5.332, nll_loss=3.788, ppl=13.81, wps=72068.1, ups=5.33, wpb=13526.9, bsz=692.6, num_updates=5800, lr=0.000830455, gnorm=0.684, train_wall=19, gb_free=19.5, wall=1168
2023-06-29 18:01:28 | INFO | train_inner | epoch 011:    340 / 556 loss=5.381, nll_loss=3.844, ppl=14.36, wps=71597.5, ups=5.37, wpb=13337.2, bsz=682.5, num_updates=5900, lr=0.000823387, gnorm=0.727, train_wall=18, gb_free=19.5, wall=1187
2023-06-29 18:01:46 | INFO | train_inner | epoch 011:    440 / 556 loss=5.437, nll_loss=3.909, ppl=15.03, wps=72528.5, ups=5.35, wpb=13556.4, bsz=658.2, num_updates=6000, lr=0.000816497, gnorm=0.711, train_wall=18, gb_free=19.3, wall=1205
2023-06-29 18:02:05 | INFO | train_inner | epoch 011:    540 / 556 loss=5.446, nll_loss=3.921, ppl=15.14, wps=72411.9, ups=5.38, wpb=13456.3, bsz=651.8, num_updates=6100, lr=0.000809776, gnorm=0.717, train_wall=18, gb_free=19.1, wall=1224
2023-06-29 18:02:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:02:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:02:08 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:02:09 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.626 | nll_loss 4.051 | ppl 16.58 | wps 214305 | wpb 9430 | bsz 473.9 | num_updates 6116 | best_loss 5.626
2023-06-29 18:02:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 6116 updates
2023-06-29 18:02:09 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint11.pt
2023-06-29 18:02:10 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint11.pt
2023-06-29 18:02:13 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint11.pt (epoch 11 @ 6116 updates, score 5.626) (writing took 3.671615883708 seconds)
2023-06-29 18:02:13 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-06-29 18:02:13 | INFO | train | epoch 011 | loss 5.369 | nll_loss 3.831 | ppl 14.24 | wps 69309.1 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 6116 | lr 0.000808716 | gnorm 0.708 | train_wall 102 | gb_free 19.3 | wall 1232
2023-06-29 18:02:13 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:02:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:02:13 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:02:13 | INFO | fairseq.trainer | begin training epoch 12
2023-06-29 18:02:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:02:28 | INFO | train_inner | epoch 012:     84 / 556 loss=5.202, nll_loss=3.639, ppl=12.46, wps=57413.6, ups=4.25, wpb=13516.5, bsz=692.3, num_updates=6200, lr=0.000803219, gnorm=0.685, train_wall=18, gb_free=19.1, wall=1248
2023-06-29 18:02:47 | INFO | train_inner | epoch 012:    184 / 556 loss=5.202, nll_loss=3.637, ppl=12.44, wps=73473.8, ups=5.36, wpb=13707.4, bsz=676.9, num_updates=6300, lr=0.000796819, gnorm=0.698, train_wall=18, gb_free=19.5, wall=1266
2023-06-29 18:03:06 | INFO | train_inner | epoch 012:    284 / 556 loss=5.228, nll_loss=3.668, ppl=12.71, wps=72709.1, ups=5.35, wpb=13593.8, bsz=677.8, num_updates=6400, lr=0.000790569, gnorm=0.694, train_wall=18, gb_free=19.3, wall=1285
2023-06-29 18:03:25 | INFO | train_inner | epoch 012:    384 / 556 loss=5.244, nll_loss=3.688, ppl=12.89, wps=72296, ups=5.27, wpb=13706.8, bsz=710.9, num_updates=6500, lr=0.000784465, gnorm=0.674, train_wall=19, gb_free=19.3, wall=1304
2023-06-29 18:03:43 | INFO | train_inner | epoch 012:    484 / 556 loss=5.313, nll_loss=3.767, ppl=13.61, wps=72928.3, ups=5.35, wpb=13622.2, bsz=673.7, num_updates=6600, lr=0.000778499, gnorm=0.704, train_wall=18, gb_free=19.5, wall=1323
2023-06-29 18:03:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:03:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:03:57 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:03:58 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.591 | nll_loss 4.007 | ppl 16.08 | wps 213043 | wpb 9430 | bsz 473.9 | num_updates 6672 | best_loss 5.591
2023-06-29 18:03:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 6672 updates
2023-06-29 18:03:58 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint12.pt
2023-06-29 18:03:59 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint12.pt
2023-06-29 18:04:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint12.pt (epoch 12 @ 6672 updates, score 5.591) (writing took 3.79397926107049 seconds)
2023-06-29 18:04:02 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-06-29 18:04:02 | INFO | train | epoch 012 | loss 5.244 | nll_loss 3.687 | ppl 12.88 | wps 69102.6 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 6672 | lr 0.000774287 | gnorm 0.694 | train_wall 103 | gb_free 19.3 | wall 1341
2023-06-29 18:04:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:04:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:04:02 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:04:02 | INFO | fairseq.trainer | begin training epoch 13
2023-06-29 18:04:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:04:07 | INFO | train_inner | epoch 013:     28 / 556 loss=5.234, nll_loss=3.677, ppl=12.79, wps=56024.2, ups=4.21, wpb=13299.3, bsz=666.7, num_updates=6700, lr=0.000772667, gnorm=0.688, train_wall=18, gb_free=19, wall=1346
2023-06-29 18:04:26 | INFO | train_inner | epoch 013:    128 / 556 loss=5.056, nll_loss=3.47, ppl=11.08, wps=71293.8, ups=5.3, wpb=13449, bsz=701.8, num_updates=6800, lr=0.000766965, gnorm=0.693, train_wall=19, gb_free=19, wall=1365
2023-06-29 18:04:45 | INFO | train_inner | epoch 013:    228 / 556 loss=5.131, nll_loss=3.554, ppl=11.74, wps=71710.3, ups=5.36, wpb=13371.8, bsz=650.2, num_updates=6900, lr=0.000761387, gnorm=0.696, train_wall=18, gb_free=19, wall=1384
2023-06-29 18:05:03 | INFO | train_inner | epoch 013:    328 / 556 loss=5.155, nll_loss=3.584, ppl=11.99, wps=72479.6, ups=5.35, wpb=13555, bsz=679.8, num_updates=7000, lr=0.000755929, gnorm=0.684, train_wall=18, gb_free=18.9, wall=1402
2023-06-29 18:05:22 | INFO | train_inner | epoch 013:    428 / 556 loss=5.166, nll_loss=3.599, ppl=12.11, wps=72533, ups=5.32, wpb=13638.9, bsz=712.1, num_updates=7100, lr=0.000750587, gnorm=0.675, train_wall=19, gb_free=19.2, wall=1421
2023-06-29 18:05:41 | INFO | train_inner | epoch 013:    528 / 556 loss=5.189, nll_loss=3.625, ppl=12.34, wps=73223, ups=5.31, wpb=13787, bsz=677, num_updates=7200, lr=0.000745356, gnorm=0.687, train_wall=19, gb_free=19.2, wall=1440
2023-06-29 18:05:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:05:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:05:46 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:05:47 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.566 | nll_loss 3.972 | ppl 15.69 | wps 215760 | wpb 9430 | bsz 473.9 | num_updates 7228 | best_loss 5.566
2023-06-29 18:05:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 7228 updates
2023-06-29 18:05:47 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint13.pt
2023-06-29 18:05:49 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint13.pt
2023-06-29 18:05:51 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint13.pt (epoch 13 @ 7228 updates, score 5.566) (writing took 3.7911548614501953 seconds)
2023-06-29 18:05:51 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-06-29 18:05:51 | INFO | train | epoch 013 | loss 5.138 | nll_loss 3.564 | ppl 11.83 | wps 68938.9 | ups 5.09 | wpb 13556 | bsz 681.8 | num_updates 7228 | lr 0.000743911 | gnorm 0.684 | train_wall 103 | gb_free 18.9 | wall 1450
2023-06-29 18:05:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:05:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:05:51 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:05:51 | INFO | fairseq.trainer | begin training epoch 14
2023-06-29 18:05:51 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:06:05 | INFO | train_inner | epoch 014:     72 / 556 loss=5.052, nll_loss=3.463, ppl=11.03, wps=57150.6, ups=4.24, wpb=13494, bsz=635.6, num_updates=7300, lr=0.000740233, gnorm=0.692, train_wall=18, gb_free=19.5, wall=1464
2023-06-29 18:06:23 | INFO | train_inner | epoch 014:    172 / 556 loss=4.99, nll_loss=3.392, ppl=10.49, wps=71888.5, ups=5.38, wpb=13359.7, bsz=684.7, num_updates=7400, lr=0.000735215, gnorm=0.692, train_wall=18, gb_free=18.9, wall=1482
2023-06-29 18:06:42 | INFO | train_inner | epoch 014:    272 / 556 loss=5.034, nll_loss=3.444, ppl=10.88, wps=72517.4, ups=5.37, wpb=13493, bsz=679.4, num_updates=7500, lr=0.000730297, gnorm=0.689, train_wall=18, gb_free=19, wall=1501
2023-06-29 18:07:00 | INFO | train_inner | epoch 014:    372 / 556 loss=5.072, nll_loss=3.487, ppl=11.21, wps=73491.1, ups=5.41, wpb=13591.6, bsz=672.5, num_updates=7600, lr=0.000725476, gnorm=0.683, train_wall=18, gb_free=19.1, wall=1519
2023-06-29 18:07:19 | INFO | train_inner | epoch 014:    472 / 556 loss=5.077, nll_loss=3.496, ppl=11.28, wps=73927.8, ups=5.39, wpb=13719.5, bsz=692.3, num_updates=7700, lr=0.00072075, gnorm=0.688, train_wall=18, gb_free=19.2, wall=1538
2023-06-29 18:07:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:07:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:07:35 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:07:36 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.559 | nll_loss 3.957 | ppl 15.53 | wps 216643 | wpb 9430 | bsz 473.9 | num_updates 7784 | best_loss 5.559
2023-06-29 18:07:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 7784 updates
2023-06-29 18:07:36 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint14.pt
2023-06-29 18:07:37 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint14.pt
2023-06-29 18:07:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint14.pt (epoch 14 @ 7784 updates, score 5.559) (writing took 3.59508640691638 seconds)
2023-06-29 18:07:39 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-06-29 18:07:39 | INFO | train | epoch 014 | loss 5.043 | nll_loss 3.455 | ppl 10.97 | wps 69671.5 | ups 5.14 | wpb 13556 | bsz 681.8 | num_updates 7784 | lr 0.00071685 | gnorm 0.687 | train_wall 102 | gb_free 19.5 | wall 1558
2023-06-29 18:07:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:07:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:07:39 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:07:39 | INFO | fairseq.trainer | begin training epoch 15
2023-06-29 18:07:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:07:42 | INFO | train_inner | epoch 015:     16 / 556 loss=5.06, nll_loss=3.477, ppl=11.14, wps=57995.8, ups=4.26, wpb=13611.6, bsz=705.9, num_updates=7800, lr=0.000716115, gnorm=0.678, train_wall=18, gb_free=19.3, wall=1561
2023-06-29 18:08:01 | INFO | train_inner | epoch 015:    116 / 556 loss=4.882, nll_loss=3.266, ppl=9.62, wps=72810.4, ups=5.36, wpb=13587.7, bsz=685.3, num_updates=7900, lr=0.000711568, gnorm=0.678, train_wall=18, gb_free=20.2, wall=1580
2023-06-29 18:08:20 | INFO | train_inner | epoch 015:    216 / 556 loss=4.953, nll_loss=3.348, ppl=10.18, wps=72544.2, ups=5.38, wpb=13489.8, bsz=661.8, num_updates=8000, lr=0.000707107, gnorm=0.699, train_wall=18, gb_free=19.3, wall=1599
2023-06-29 18:08:38 | INFO | train_inner | epoch 015:    316 / 556 loss=4.978, nll_loss=3.377, ppl=10.39, wps=72089.1, ups=5.37, wpb=13425.3, bsz=668.6, num_updates=8100, lr=0.000702728, gnorm=0.681, train_wall=18, gb_free=19, wall=1617
2023-06-29 18:08:57 | INFO | train_inner | epoch 015:    416 / 556 loss=4.991, nll_loss=3.395, ppl=10.52, wps=73251.7, ups=5.36, wpb=13657.9, bsz=679.3, num_updates=8200, lr=0.00069843, gnorm=0.679, train_wall=18, gb_free=19.2, wall=1636
2023-06-29 18:09:15 | INFO | train_inner | epoch 015:    516 / 556 loss=5.005, nll_loss=3.412, ppl=10.65, wps=73465.5, ups=5.37, wpb=13671, bsz=699.5, num_updates=8300, lr=0.00069421, gnorm=0.672, train_wall=18, gb_free=19, wall=1655
2023-06-29 18:09:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:09:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:09:23 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:09:24 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 5.553 | nll_loss 3.947 | ppl 15.42 | wps 215934 | wpb 9430 | bsz 473.9 | num_updates 8340 | best_loss 5.553
2023-06-29 18:09:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 8340 updates
2023-06-29 18:09:24 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint15.pt
2023-06-29 18:09:25 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint15.pt
2023-06-29 18:09:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint15.pt (epoch 15 @ 8340 updates, score 5.553) (writing took 3.623150359839201 seconds)
2023-06-29 18:09:28 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-06-29 18:09:28 | INFO | train | epoch 015 | loss 4.961 | nll_loss 3.36 | ppl 10.26 | wps 69594.2 | ups 5.13 | wpb 13556 | bsz 681.8 | num_updates 8340 | lr 0.000692543 | gnorm 0.681 | train_wall 102 | gb_free 19.4 | wall 1667
2023-06-29 18:09:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:09:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:09:28 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:09:28 | INFO | fairseq.trainer | begin training epoch 16
2023-06-29 18:09:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:09:39 | INFO | train_inner | epoch 016:     60 / 556 loss=4.871, nll_loss=3.256, ppl=9.55, wps=57078, ups=4.27, wpb=13378.5, bsz=696.8, num_updates=8400, lr=0.000690066, gnorm=0.667, train_wall=18, gb_free=19, wall=1678
2023-06-29 18:09:58 | INFO | train_inner | epoch 016:    160 / 556 loss=4.802, nll_loss=3.175, ppl=9.03, wps=73350.9, ups=5.33, wpb=13750.4, bsz=702.6, num_updates=8500, lr=0.000685994, gnorm=0.685, train_wall=18, gb_free=19.7, wall=1697
2023-06-29 18:10:16 | INFO | train_inner | epoch 016:    260 / 556 loss=4.871, nll_loss=3.253, ppl=9.53, wps=72446.4, ups=5.31, wpb=13632.4, bsz=671.8, num_updates=8600, lr=0.000681994, gnorm=0.708, train_wall=19, gb_free=19.1, wall=1716
2023-06-29 18:10:35 | INFO | train_inner | epoch 016:    360 / 556 loss=4.906, nll_loss=3.296, ppl=9.82, wps=71808.8, ups=5.38, wpb=13350.2, bsz=714.5, num_updates=8700, lr=0.000678064, gnorm=0.706, train_wall=18, gb_free=19.9, wall=1734
2023-06-29 18:10:54 | INFO | train_inner | epoch 016:    460 / 556 loss=4.949, nll_loss=3.345, ppl=10.16, wps=73430.4, ups=5.39, wpb=13624.6, bsz=664.3, num_updates=8800, lr=0.0006742, gnorm=0.673, train_wall=18, gb_free=19.1, wall=1753
2023-06-29 18:11:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:11:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:11:12 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:11:12 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 5.535 | nll_loss 3.919 | ppl 15.13 | wps 215132 | wpb 9430 | bsz 473.9 | num_updates 8896 | best_loss 5.535
2023-06-29 18:11:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 8896 updates
2023-06-29 18:11:12 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint16.pt
2023-06-29 18:11:14 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint16.pt
2023-06-29 18:11:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint16.pt (epoch 16 @ 8896 updates, score 5.535) (writing took 3.5225328728556633 seconds)
2023-06-29 18:11:16 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-06-29 18:11:16 | INFO | train | epoch 016 | loss 4.886 | nll_loss 3.272 | ppl 9.66 | wps 69433.8 | ups 5.12 | wpb 13556 | bsz 681.8 | num_updates 8896 | lr 0.000670552 | gnorm 0.689 | train_wall 102 | gb_free 19.3 | wall 1775
2023-06-29 18:11:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:11:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:11:16 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:11:16 | INFO | fairseq.trainer | begin training epoch 17
2023-06-29 18:11:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:11:17 | INFO | train_inner | epoch 017:      4 / 556 loss=4.951, nll_loss=3.348, ppl=10.18, wps=58047.3, ups=4.28, wpb=13554.5, bsz=669.8, num_updates=8900, lr=0.000670402, gnorm=0.683, train_wall=18, gb_free=19.7, wall=1776
2023-06-29 18:11:36 | INFO | train_inner | epoch 017:    104 / 556 loss=4.732, nll_loss=3.091, ppl=8.52, wps=72795, ups=5.36, wpb=13578.5, bsz=681.1, num_updates=9000, lr=0.000666667, gnorm=0.667, train_wall=18, gb_free=19.3, wall=1795
2023-06-29 18:11:54 | INFO | train_inner | epoch 017:    204 / 556 loss=4.774, nll_loss=3.14, ppl=8.81, wps=72047.9, ups=5.32, wpb=13543.9, bsz=676.1, num_updates=9100, lr=0.000662994, gnorm=0.688, train_wall=19, gb_free=19.8, wall=1814
2023-06-29 18:12:13 | INFO | train_inner | epoch 017:    304 / 556 loss=4.832, nll_loss=3.207, ppl=9.24, wps=71224.5, ups=5.32, wpb=13383.6, bsz=668.9, num_updates=9200, lr=0.00065938, gnorm=0.703, train_wall=19, gb_free=19.2, wall=1832
2023-06-29 18:12:32 | INFO | train_inner | epoch 017:    404 / 556 loss=4.862, nll_loss=3.243, ppl=9.47, wps=72447, ups=5.34, wpb=13571.9, bsz=665.9, num_updates=9300, lr=0.000655826, gnorm=0.671, train_wall=18, gb_free=19.1, wall=1851
2023-06-29 18:12:51 | INFO | train_inner | epoch 017:    504 / 556 loss=4.859, nll_loss=3.243, ppl=9.47, wps=73149.8, ups=5.36, wpb=13651.7, bsz=714.5, num_updates=9400, lr=0.000652328, gnorm=0.672, train_wall=18, gb_free=19.8, wall=1870
2023-06-29 18:13:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:13:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:13:00 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:13:01 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 5.524 | nll_loss 3.922 | ppl 15.16 | wps 211442 | wpb 9430 | bsz 473.9 | num_updates 9452 | best_loss 5.524
2023-06-29 18:13:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 9452 updates
2023-06-29 18:13:01 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint17.pt
2023-06-29 18:13:03 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint17.pt
2023-06-29 18:13:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint17.pt (epoch 17 @ 9452 updates, score 5.524) (writing took 3.639706626534462 seconds)
2023-06-29 18:13:05 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-06-29 18:13:05 | INFO | train | epoch 017 | loss 4.816 | nll_loss 3.19 | ppl 9.12 | wps 69217.6 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 9452 | lr 0.000650531 | gnorm 0.68 | train_wall 103 | gb_free 18.9 | wall 1884
2023-06-29 18:13:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:13:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:13:05 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:13:05 | INFO | fairseq.trainer | begin training epoch 18
2023-06-29 18:13:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:13:14 | INFO | train_inner | epoch 018:     48 / 556 loss=4.767, nll_loss=3.134, ppl=8.78, wps=57641.3, ups=4.28, wpb=13475.6, bsz=673.6, num_updates=9500, lr=0.000648886, gnorm=0.673, train_wall=18, gb_free=19.3, wall=1893
2023-06-29 18:13:33 | INFO | train_inner | epoch 018:    148 / 556 loss=4.685, nll_loss=3.036, ppl=8.2, wps=73150.3, ups=5.38, wpb=13586.5, bsz=673.9, num_updates=9600, lr=0.000645497, gnorm=0.686, train_wall=18, gb_free=19, wall=1912
2023-06-29 18:13:51 | INFO | train_inner | epoch 018:    248 / 556 loss=4.729, nll_loss=3.088, ppl=8.5, wps=71488, ups=5.28, wpb=13529.1, bsz=682.1, num_updates=9700, lr=0.000642161, gnorm=0.678, train_wall=19, gb_free=19.1, wall=1931
2023-06-29 18:14:10 | INFO | train_inner | epoch 018:    348 / 556 loss=4.803, nll_loss=3.172, ppl=9.02, wps=72273.7, ups=5.32, wpb=13594.2, bsz=652.6, num_updates=9800, lr=0.000638877, gnorm=0.701, train_wall=19, gb_free=19, wall=1949
2023-06-29 18:14:29 | INFO | train_inner | epoch 018:    448 / 556 loss=4.77, nll_loss=3.138, ppl=8.8, wps=72694.4, ups=5.34, wpb=13620.7, bsz=708.6, num_updates=9900, lr=0.000635642, gnorm=0.657, train_wall=18, gb_free=19, wall=1968
2023-06-29 18:14:48 | INFO | train_inner | epoch 018:    548 / 556 loss=4.822, nll_loss=3.198, ppl=9.18, wps=72189.4, ups=5.34, wpb=13530.4, bsz=692.9, num_updates=10000, lr=0.000632456, gnorm=0.7, train_wall=18, gb_free=19.2, wall=1987
2023-06-29 18:14:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:14:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:14:49 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:14:50 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 5.524 | nll_loss 3.925 | ppl 15.18 | wps 213767 | wpb 9430 | bsz 473.9 | num_updates 10008 | best_loss 5.524
2023-06-29 18:14:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 10008 updates
2023-06-29 18:14:50 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint18.pt
2023-06-29 18:14:52 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint18.pt
2023-06-29 18:14:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint18.pt (epoch 18 @ 10008 updates, score 5.524) (writing took 3.77089324593544 seconds)
2023-06-29 18:14:54 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-06-29 18:14:54 | INFO | train | epoch 018 | loss 4.754 | nll_loss 3.118 | ppl 8.68 | wps 69065.1 | ups 5.09 | wpb 13556 | bsz 681.8 | num_updates 10008 | lr 0.000632203 | gnorm 0.683 | train_wall 103 | gb_free 19.5 | wall 1993
2023-06-29 18:14:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:14:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:14:54 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:14:54 | INFO | fairseq.trainer | begin training epoch 19
2023-06-29 18:14:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:15:11 | INFO | train_inner | epoch 019:     92 / 556 loss=4.614, nll_loss=2.955, ppl=7.75, wps=57026.4, ups=4.22, wpb=13507.1, bsz=703, num_updates=10100, lr=0.000629317, gnorm=0.669, train_wall=18, gb_free=19.2, wall=2011
2023-06-29 18:15:30 | INFO | train_inner | epoch 019:    192 / 556 loss=4.654, nll_loss=2.999, ppl=8, wps=72875.5, ups=5.36, wpb=13587.1, bsz=674.5, num_updates=10200, lr=0.000626224, gnorm=0.689, train_wall=18, gb_free=19.2, wall=2029
2023-06-29 18:15:49 | INFO | train_inner | epoch 019:    292 / 556 loss=4.681, nll_loss=3.033, ppl=8.19, wps=71681.3, ups=5.31, wpb=13492.9, bsz=702.2, num_updates=10300, lr=0.000623177, gnorm=0.679, train_wall=19, gb_free=19.4, wall=2048
2023-06-29 18:16:07 | INFO | train_inner | epoch 019:    392 / 556 loss=4.756, nll_loss=3.119, ppl=8.69, wps=72307.4, ups=5.38, wpb=13430, bsz=668.3, num_updates=10400, lr=0.000620174, gnorm=0.712, train_wall=18, gb_free=18.9, wall=2067
2023-06-29 18:16:26 | INFO | train_inner | epoch 019:    492 / 556 loss=4.757, nll_loss=3.121, ppl=8.7, wps=72536.6, ups=5.36, wpb=13529.1, bsz=667.6, num_updates=10500, lr=0.000617213, gnorm=0.683, train_wall=18, gb_free=19.3, wall=2085
2023-06-29 18:16:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:16:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:16:38 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:16:39 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 5.535 | nll_loss 3.921 | ppl 15.15 | wps 214214 | wpb 9430 | bsz 473.9 | num_updates 10564 | best_loss 5.524
2023-06-29 18:16:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 10564 updates
2023-06-29 18:16:39 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint19.pt
2023-06-29 18:16:41 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint19.pt
2023-06-29 18:16:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint19.pt (epoch 19 @ 10564 updates, score 5.535) (writing took 2.668076440691948 seconds)
2023-06-29 18:16:42 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-06-29 18:16:42 | INFO | train | epoch 019 | loss 4.698 | nll_loss 3.052 | ppl 8.29 | wps 69981.8 | ups 5.16 | wpb 13556 | bsz 681.8 | num_updates 10564 | lr 0.000615341 | gnorm 0.684 | train_wall 102 | gb_free 19.1 | wall 2101
2023-06-29 18:16:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:16:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:16:42 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:16:42 | INFO | fairseq.trainer | begin training epoch 20
2023-06-29 18:16:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:16:49 | INFO | train_inner | epoch 020:     36 / 556 loss=4.669, nll_loss=3.02, ppl=8.11, wps=61586.6, ups=4.45, wpb=13853.4, bsz=695.9, num_updates=10600, lr=0.000614295, gnorm=0.66, train_wall=18, gb_free=18.9, wall=2108
2023-06-29 18:17:07 | INFO | train_inner | epoch 020:    136 / 556 loss=4.578, nll_loss=2.909, ppl=7.51, wps=71372.7, ups=5.36, wpb=13308.2, bsz=651.4, num_updates=10700, lr=0.000611418, gnorm=0.668, train_wall=18, gb_free=19.4, wall=2126
2023-06-29 18:17:26 | INFO | train_inner | epoch 020:    236 / 556 loss=4.604, nll_loss=2.941, ppl=7.68, wps=72712.5, ups=5.37, wpb=13528.1, bsz=688.3, num_updates=10800, lr=0.000608581, gnorm=0.685, train_wall=18, gb_free=19.4, wall=2145
2023-06-29 18:17:45 | INFO | train_inner | epoch 020:    336 / 556 loss=4.659, nll_loss=3.007, ppl=8.04, wps=72810.4, ups=5.35, wpb=13618.2, bsz=682.6, num_updates=10900, lr=0.000605783, gnorm=0.675, train_wall=18, gb_free=19.1, wall=2164
2023-06-29 18:18:03 | INFO | train_inner | epoch 020:    436 / 556 loss=4.692, nll_loss=3.045, ppl=8.25, wps=72346.7, ups=5.3, wpb=13650.9, bsz=685.8, num_updates=11000, lr=0.000603023, gnorm=0.685, train_wall=19, gb_free=18.9, wall=2183
2023-06-29 18:18:22 | INFO | train_inner | epoch 020:    536 / 556 loss=4.725, nll_loss=3.085, ppl=8.48, wps=72186.3, ups=5.35, wpb=13497.4, bsz=673.7, num_updates=11100, lr=0.0006003, gnorm=0.686, train_wall=18, gb_free=19, wall=2201
2023-06-29 18:18:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:18:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:18:26 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:18:27 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 5.537 | nll_loss 3.916 | ppl 15.09 | wps 213429 | wpb 9430 | bsz 473.9 | num_updates 11120 | best_loss 5.524
2023-06-29 18:18:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 11120 updates
2023-06-29 18:18:27 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint20.pt
2023-06-29 18:18:28 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint20.pt
2023-06-29 18:18:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint20.pt (epoch 20 @ 11120 updates, score 5.537) (writing took 2.6872732266783714 seconds)
2023-06-29 18:18:30 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-06-29 18:18:30 | INFO | train | epoch 020 | loss 4.643 | nll_loss 2.988 | ppl 7.93 | wps 69883.1 | ups 5.16 | wpb 13556 | bsz 681.8 | num_updates 11120 | lr 0.00059976 | gnorm 0.677 | train_wall 103 | gb_free 19.1 | wall 2209
2023-06-29 18:18:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:18:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:18:30 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:18:30 | INFO | fairseq.trainer | begin training epoch 21
2023-06-29 18:18:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:18:45 | INFO | train_inner | epoch 021:     80 / 556 loss=4.517, nll_loss=2.841, ppl=7.17, wps=61207.6, ups=4.43, wpb=13824, bsz=691.3, num_updates=11200, lr=0.000597614, gnorm=0.683, train_wall=18, gb_free=19.4, wall=2224
2023-06-29 18:19:03 | INFO | train_inner | epoch 021:    180 / 556 loss=4.517, nll_loss=2.841, ppl=7.17, wps=74011.4, ups=5.34, wpb=13867.5, bsz=705.8, num_updates=11300, lr=0.000594964, gnorm=0.661, train_wall=18, gb_free=19.6, wall=2243
2023-06-29 18:19:22 | INFO | train_inner | epoch 021:    280 / 556 loss=4.62, nll_loss=2.959, ppl=7.78, wps=72526.5, ups=5.37, wpb=13507.7, bsz=671.4, num_updates=11400, lr=0.000592349, gnorm=0.718, train_wall=18, gb_free=19.8, wall=2261
2023-06-29 18:19:41 | INFO | train_inner | epoch 021:    380 / 556 loss=4.615, nll_loss=2.955, ppl=7.75, wps=72570.7, ups=5.34, wpb=13580.9, bsz=682.1, num_updates=11500, lr=0.000589768, gnorm=0.668, train_wall=18, gb_free=19.4, wall=2280
2023-06-29 18:19:59 | INFO | train_inner | epoch 021:    480 / 556 loss=4.645, nll_loss=2.992, ppl=7.96, wps=71119.7, ups=5.36, wpb=13264.4, bsz=695.9, num_updates=11600, lr=0.00058722, gnorm=0.681, train_wall=18, gb_free=18.9, wall=2299
2023-06-29 18:20:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:20:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:20:14 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:20:15 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 5.542 | nll_loss 3.933 | ppl 15.27 | wps 212785 | wpb 9430 | bsz 473.9 | num_updates 11676 | best_loss 5.524
2023-06-29 18:20:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 11676 updates
2023-06-29 18:20:15 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint21.pt
2023-06-29 18:20:17 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint21.pt
2023-06-29 18:20:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint21.pt (epoch 21 @ 11676 updates, score 5.542) (writing took 2.96092389523983 seconds)
2023-06-29 18:20:18 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-06-29 18:20:18 | INFO | train | epoch 021 | loss 4.594 | nll_loss 2.93 | ppl 7.62 | wps 69516.4 | ups 5.13 | wpb 13556 | bsz 681.8 | num_updates 11676 | lr 0.000585306 | gnorm 0.685 | train_wall 103 | gb_free 19.2 | wall 2317
2023-06-29 18:20:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:20:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:20:18 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:20:18 | INFO | fairseq.trainer | begin training epoch 22
2023-06-29 18:20:18 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:20:23 | INFO | train_inner | epoch 022:     24 / 556 loss=4.631, nll_loss=2.974, ppl=7.86, wps=57949.9, ups=4.3, wpb=13467.6, bsz=657.9, num_updates=11700, lr=0.000584705, gnorm=0.694, train_wall=19, gb_free=19.8, wall=2322
2023-06-29 18:20:41 | INFO | train_inner | epoch 022:    124 / 556 loss=4.472, nll_loss=2.786, ppl=6.9, wps=72522.6, ups=5.38, wpb=13489, bsz=687.8, num_updates=11800, lr=0.000582223, gnorm=0.682, train_wall=18, gb_free=19.4, wall=2340
2023-06-29 18:21:00 | INFO | train_inner | epoch 022:    224 / 556 loss=4.511, nll_loss=2.832, ppl=7.12, wps=72805.9, ups=5.35, wpb=13616.9, bsz=672, num_updates=11900, lr=0.000579771, gnorm=0.685, train_wall=18, gb_free=19.8, wall=2359
2023-06-29 18:21:19 | INFO | train_inner | epoch 022:    324 / 556 loss=4.569, nll_loss=2.9, ppl=7.47, wps=72681.3, ups=5.37, wpb=13536.6, bsz=677, num_updates=12000, lr=0.00057735, gnorm=0.695, train_wall=18, gb_free=19.5, wall=2378
2023-06-29 18:21:37 | INFO | train_inner | epoch 022:    424 / 556 loss=4.593, nll_loss=2.928, ppl=7.61, wps=71539.1, ups=5.33, wpb=13425.1, bsz=656.5, num_updates=12100, lr=0.00057496, gnorm=0.7, train_wall=18, gb_free=19.3, wall=2397
2023-06-29 18:21:56 | INFO | train_inner | epoch 022:    524 / 556 loss=4.609, nll_loss=2.949, ppl=7.72, wps=72188.4, ups=5.32, wpb=13574.6, bsz=680.2, num_updates=12200, lr=0.000572598, gnorm=0.679, train_wall=19, gb_free=19.6, wall=2415
2023-06-29 18:22:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:22:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:22:02 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:22:03 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 5.555 | nll_loss 3.932 | ppl 15.26 | wps 215303 | wpb 9430 | bsz 473.9 | num_updates 12232 | best_loss 5.524
2023-06-29 18:22:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 12232 updates
2023-06-29 18:22:03 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint22.pt
2023-06-29 18:22:05 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint22.pt
2023-06-29 18:22:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint22.pt (epoch 22 @ 12232 updates, score 5.555) (writing took 2.8195430114865303 seconds)
2023-06-29 18:22:06 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-06-29 18:22:06 | INFO | train | epoch 022 | loss 4.547 | nll_loss 2.875 | ppl 7.34 | wps 69784.9 | ups 5.15 | wpb 13556 | bsz 681.8 | num_updates 12232 | lr 0.000571849 | gnorm 0.687 | train_wall 103 | gb_free 19.2 | wall 2425
2023-06-29 18:22:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:22:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:22:06 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:22:06 | INFO | fairseq.trainer | begin training epoch 23
2023-06-29 18:22:06 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:22:19 | INFO | train_inner | epoch 023:     68 / 556 loss=4.456, nll_loss=2.77, ppl=6.82, wps=59948.6, ups=4.39, wpb=13664.8, bsz=715.5, num_updates=12300, lr=0.000570266, gnorm=0.679, train_wall=19, gb_free=19.8, wall=2438
2023-06-29 18:22:38 | INFO | train_inner | epoch 023:    168 / 556 loss=4.466, nll_loss=2.777, ppl=6.86, wps=71713.8, ups=5.35, wpb=13406, bsz=654.6, num_updates=12400, lr=0.000567962, gnorm=0.702, train_wall=18, gb_free=19.1, wall=2457
2023-06-29 18:22:56 | INFO | train_inner | epoch 023:    268 / 556 loss=4.485, nll_loss=2.803, ppl=6.98, wps=72362.8, ups=5.32, wpb=13590.5, bsz=678.1, num_updates=12500, lr=0.000565685, gnorm=0.684, train_wall=19, gb_free=19.6, wall=2476
2023-06-29 18:23:15 | INFO | train_inner | epoch 023:    368 / 556 loss=4.525, nll_loss=2.848, ppl=7.2, wps=73051.1, ups=5.38, wpb=13582, bsz=679.3, num_updates=12600, lr=0.000563436, gnorm=0.679, train_wall=18, gb_free=19.1, wall=2494
2023-06-29 18:23:34 | INFO | train_inner | epoch 023:    468 / 556 loss=4.566, nll_loss=2.897, ppl=7.45, wps=71861, ups=5.37, wpb=13384.4, bsz=697.6, num_updates=12700, lr=0.000561214, gnorm=0.707, train_wall=18, gb_free=19.5, wall=2513
2023-06-29 18:23:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:23:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:23:50 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:23:51 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 5.561 | nll_loss 3.95 | ppl 15.45 | wps 215726 | wpb 9430 | bsz 473.9 | num_updates 12788 | best_loss 5.524
2023-06-29 18:23:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 12788 updates
2023-06-29 18:23:51 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint23.pt
2023-06-29 18:23:53 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint23.pt
2023-06-29 18:23:54 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint23.pt (epoch 23 @ 12788 updates, score 5.561) (writing took 2.823089327663183 seconds)
2023-06-29 18:23:54 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-06-29 18:23:54 | INFO | train | epoch 023 | loss 4.505 | nll_loss 2.825 | ppl 7.09 | wps 69867.9 | ups 5.15 | wpb 13556 | bsz 681.8 | num_updates 12788 | lr 0.000559279 | gnorm 0.687 | train_wall 102 | gb_free 19.3 | wall 2533
2023-06-29 18:23:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:23:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:23:54 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:23:54 | INFO | fairseq.trainer | begin training epoch 24
2023-06-29 18:23:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:23:56 | INFO | train_inner | epoch 024:     12 / 556 loss=4.537, nll_loss=2.865, ppl=7.28, wps=61051.8, ups=4.42, wpb=13818.4, bsz=691.4, num_updates=12800, lr=0.000559017, gnorm=0.666, train_wall=18, gb_free=19, wall=2535
2023-06-29 18:24:15 | INFO | train_inner | epoch 024:    112 / 556 loss=4.358, nll_loss=2.654, ppl=6.29, wps=73321.7, ups=5.34, wpb=13737.6, bsz=682.5, num_updates=12900, lr=0.000556846, gnorm=0.652, train_wall=18, gb_free=18.8, wall=2554
2023-06-29 18:24:34 | INFO | train_inner | epoch 024:    212 / 556 loss=4.44, nll_loss=2.748, ppl=6.72, wps=72542.8, ups=5.33, wpb=13598.1, bsz=672.1, num_updates=13000, lr=0.0005547, gnorm=0.696, train_wall=18, gb_free=18.9, wall=2573
2023-06-29 18:24:52 | INFO | train_inner | epoch 024:    312 / 556 loss=4.489, nll_loss=2.805, ppl=6.99, wps=71978.4, ups=5.35, wpb=13445, bsz=628.9, num_updates=13100, lr=0.000552579, gnorm=0.715, train_wall=18, gb_free=19, wall=2592
2023-06-29 18:25:11 | INFO | train_inner | epoch 024:    412 / 556 loss=4.475, nll_loss=2.792, ppl=6.93, wps=72662.9, ups=5.35, wpb=13590.1, bsz=708.7, num_updates=13200, lr=0.000550482, gnorm=0.676, train_wall=18, gb_free=19.6, wall=2610
2023-06-29 18:25:30 | INFO | train_inner | epoch 024:    512 / 556 loss=4.534, nll_loss=2.86, ppl=7.26, wps=71094.6, ups=5.32, wpb=13366.5, bsz=696.4, num_updates=13300, lr=0.000548408, gnorm=0.722, train_wall=19, gb_free=19.7, wall=2629
2023-06-29 18:25:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:25:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:25:38 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:25:39 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 5.566 | nll_loss 3.956 | ppl 15.52 | wps 215320 | wpb 9430 | bsz 473.9 | num_updates 13344 | best_loss 5.524
2023-06-29 18:25:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 13344 updates
2023-06-29 18:25:39 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint24.pt
2023-06-29 18:25:41 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint24.pt
2023-06-29 18:25:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint24.pt (epoch 24 @ 13344 updates, score 5.566) (writing took 2.2601904310286045 seconds)
2023-06-29 18:25:42 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-06-29 18:25:42 | INFO | train | epoch 024 | loss 4.464 | nll_loss 2.778 | ppl 6.86 | wps 70046.9 | ups 5.17 | wpb 13556 | bsz 681.8 | num_updates 13344 | lr 0.000547504 | gnorm 0.693 | train_wall 103 | gb_free 19 | wall 2641
2023-06-29 18:25:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:25:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:25:42 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:25:42 | INFO | fairseq.trainer | begin training epoch 25
2023-06-29 18:25:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:25:52 | INFO | train_inner | epoch 025:     56 / 556 loss=4.419, nll_loss=2.726, ppl=6.62, wps=61357.7, ups=4.51, wpb=13611.2, bsz=718.8, num_updates=13400, lr=0.000546358, gnorm=0.697, train_wall=19, gb_free=19.2, wall=2651
2023-06-29 18:26:11 | INFO | train_inner | epoch 025:    156 / 556 loss=4.354, nll_loss=2.648, ppl=6.27, wps=72495.7, ups=5.36, wpb=13533.1, bsz=682.3, num_updates=13500, lr=0.000544331, gnorm=0.681, train_wall=18, gb_free=19.5, wall=2670
2023-06-29 18:26:30 | INFO | train_inner | epoch 025:    256 / 556 loss=4.413, nll_loss=2.718, ppl=6.58, wps=71754.6, ups=5.3, wpb=13534.8, bsz=677.2, num_updates=13600, lr=0.000542326, gnorm=0.687, train_wall=19, gb_free=19.5, wall=2689
2023-06-29 18:26:48 | INFO | train_inner | epoch 025:    356 / 556 loss=4.433, nll_loss=2.741, ppl=6.69, wps=72544.4, ups=5.33, wpb=13618.2, bsz=666.5, num_updates=13700, lr=0.000540343, gnorm=0.7, train_wall=19, gb_free=19, wall=2708
2023-06-29 18:27:07 | INFO | train_inner | epoch 025:    456 / 556 loss=4.476, nll_loss=2.793, ppl=6.93, wps=71802.2, ups=5.34, wpb=13445.3, bsz=698.3, num_updates=13800, lr=0.000538382, gnorm=0.687, train_wall=18, gb_free=19.2, wall=2726
2023-06-29 18:27:26 | INFO | train_inner | epoch 025:    556 / 556 loss=4.516, nll_loss=2.839, ppl=7.16, wps=72875.3, ups=5.35, wpb=13616.4, bsz=674.6, num_updates=13900, lr=0.000536442, gnorm=0.671, train_wall=18, gb_free=19.1, wall=2745
2023-06-29 18:27:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:27:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:27:26 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:27:27 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 5.585 | nll_loss 3.966 | ppl 15.63 | wps 212719 | wpb 9430 | bsz 473.9 | num_updates 13900 | best_loss 5.524
2023-06-29 18:27:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 13900 updates
2023-06-29 18:27:27 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint25.pt
2023-06-29 18:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint25.pt
2023-06-29 18:27:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint25.pt (epoch 25 @ 13900 updates, score 5.585) (writing took 2.731773264706135 seconds)
2023-06-29 18:27:30 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-06-29 18:27:30 | INFO | train | epoch 025 | loss 4.425 | nll_loss 2.732 | ppl 6.65 | wps 69703.2 | ups 5.14 | wpb 13556 | bsz 681.8 | num_updates 13900 | lr 0.000536442 | gnorm 0.686 | train_wall 103 | gb_free 19.1 | wall 2749
2023-06-29 18:27:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:27:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:27:30 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:27:30 | INFO | fairseq.trainer | begin training epoch 26
2023-06-29 18:27:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:27:48 | INFO | train_inner | epoch 026:    100 / 556 loss=4.276, nll_loss=2.559, ppl=5.89, wps=60329.4, ups=4.43, wpb=13625.4, bsz=718.9, num_updates=14000, lr=0.000534522, gnorm=0.667, train_wall=18, gb_free=18.9, wall=2768
2023-06-29 18:28:07 | INFO | train_inner | epoch 026:    200 / 556 loss=4.327, nll_loss=2.618, ppl=6.14, wps=72194.1, ups=5.35, wpb=13485.6, bsz=686.2, num_updates=14100, lr=0.000532624, gnorm=0.695, train_wall=18, gb_free=19, wall=2786
2023-06-29 18:28:26 | INFO | train_inner | epoch 026:    300 / 556 loss=4.415, nll_loss=2.718, ppl=6.58, wps=72454.6, ups=5.34, wpb=13567.4, bsz=659.4, num_updates=14200, lr=0.000530745, gnorm=0.709, train_wall=18, gb_free=19.3, wall=2805
2023-06-29 18:28:45 | INFO | train_inner | epoch 026:    400 / 556 loss=4.422, nll_loss=2.729, ppl=6.63, wps=72869.4, ups=5.33, wpb=13673.4, bsz=690.6, num_updates=14300, lr=0.000528886, gnorm=0.676, train_wall=18, gb_free=19, wall=2824
2023-06-29 18:29:03 | INFO | train_inner | epoch 026:    500 / 556 loss=4.481, nll_loss=2.797, ppl=6.95, wps=72310.1, ups=5.37, wpb=13458.3, bsz=650.7, num_updates=14400, lr=0.000527046, gnorm=0.731, train_wall=18, gb_free=19.5, wall=2842
2023-06-29 18:29:14 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:29:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:29:14 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:29:15 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 5.599 | nll_loss 3.983 | ppl 15.81 | wps 214961 | wpb 9430 | bsz 473.9 | num_updates 14456 | best_loss 5.524
2023-06-29 18:29:15 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 14456 updates
2023-06-29 18:29:15 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint26.pt
2023-06-29 18:29:16 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint26.pt
2023-06-29 18:29:17 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint26.pt (epoch 26 @ 14456 updates, score 5.599) (writing took 2.6424533389508724 seconds)
2023-06-29 18:29:17 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-06-29 18:29:17 | INFO | train | epoch 026 | loss 4.39 | nll_loss 2.691 | ppl 6.46 | wps 70060.1 | ups 5.17 | wpb 13556 | bsz 681.8 | num_updates 14456 | lr 0.000526024 | gnorm 0.695 | train_wall 102 | gb_free 18.9 | wall 2856
2023-06-29 18:29:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:29:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:29:17 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:29:17 | INFO | fairseq.trainer | begin training epoch 27
2023-06-29 18:29:17 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:29:26 | INFO | train_inner | epoch 027:     44 / 556 loss=4.36, nll_loss=2.656, ppl=6.3, wps=60507.9, ups=4.47, wpb=13543.1, bsz=695.5, num_updates=14500, lr=0.000525226, gnorm=0.702, train_wall=18, gb_free=19.1, wall=2865
2023-06-29 18:29:44 | INFO | train_inner | epoch 027:    144 / 556 loss=4.283, nll_loss=2.564, ppl=5.91, wps=72862.1, ups=5.4, wpb=13484.2, bsz=673.9, num_updates=14600, lr=0.000523424, gnorm=0.688, train_wall=18, gb_free=19, wall=2883
2023-06-29 18:30:03 | INFO | train_inner | epoch 027:    244 / 556 loss=4.319, nll_loss=2.609, ppl=6.1, wps=72778.6, ups=5.35, wpb=13599.4, bsz=714.6, num_updates=14700, lr=0.000521641, gnorm=0.685, train_wall=18, gb_free=19.1, wall=2902
2023-06-29 18:30:22 | INFO | train_inner | epoch 027:    344 / 556 loss=4.371, nll_loss=2.669, ppl=6.36, wps=71596.9, ups=5.3, wpb=13502.6, bsz=664.4, num_updates=14800, lr=0.000519875, gnorm=0.692, train_wall=19, gb_free=19.4, wall=2921
2023-06-29 18:30:41 | INFO | train_inner | epoch 027:    444 / 556 loss=4.415, nll_loss=2.721, ppl=6.59, wps=72464.8, ups=5.31, wpb=13639.4, bsz=664.6, num_updates=14900, lr=0.000518128, gnorm=0.72, train_wall=19, gb_free=19.1, wall=2940
2023-06-29 18:30:59 | INFO | train_inner | epoch 027:    544 / 556 loss=4.433, nll_loss=2.742, ppl=6.69, wps=72014.3, ups=5.34, wpb=13479.9, bsz=673.7, num_updates=15000, lr=0.000516398, gnorm=0.718, train_wall=18, gb_free=19.6, wall=2958
2023-06-29 18:31:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:31:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:31:01 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:31:02 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 5.599 | nll_loss 3.99 | ppl 15.89 | wps 215143 | wpb 9430 | bsz 473.9 | num_updates 15012 | best_loss 5.524
2023-06-29 18:31:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 15012 updates
2023-06-29 18:31:02 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint27.pt
2023-06-29 18:31:04 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint27.pt
2023-06-29 18:31:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint27.pt (epoch 27 @ 15012 updates, score 5.599) (writing took 2.626716982573271 seconds)
2023-06-29 18:31:05 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-06-29 18:31:05 | INFO | train | epoch 027 | loss 4.356 | nll_loss 2.651 | ppl 6.28 | wps 69850.2 | ups 5.15 | wpb 13556 | bsz 681.8 | num_updates 15012 | lr 0.000516191 | gnorm 0.701 | train_wall 103 | gb_free 19.4 | wall 2964
2023-06-29 18:31:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:31:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:31:05 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:31:05 | INFO | fairseq.trainer | begin training epoch 28
2023-06-29 18:31:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:31:22 | INFO | train_inner | epoch 028:     88 / 556 loss=4.242, nll_loss=2.518, ppl=5.73, wps=60118.1, ups=4.41, wpb=13635.7, bsz=691.7, num_updates=15100, lr=0.000514685, gnorm=0.694, train_wall=19, gb_free=18.8, wall=2981
2023-06-29 18:31:41 | INFO | train_inner | epoch 028:    188 / 556 loss=4.289, nll_loss=2.571, ppl=5.94, wps=72293.5, ups=5.37, wpb=13469.5, bsz=669.7, num_updates=15200, lr=0.000512989, gnorm=0.713, train_wall=18, gb_free=19, wall=3000
2023-06-29 18:31:59 | INFO | train_inner | epoch 028:    288 / 556 loss=4.298, nll_loss=2.584, ppl=5.99, wps=72037.1, ups=5.36, wpb=13442.7, bsz=676.4, num_updates=15300, lr=0.00051131, gnorm=0.674, train_wall=18, gb_free=19, wall=3018
2023-06-29 18:32:18 | INFO | train_inner | epoch 028:    388 / 556 loss=4.344, nll_loss=2.637, ppl=6.22, wps=72688.1, ups=5.34, wpb=13603.9, bsz=689.2, num_updates=15400, lr=0.000509647, gnorm=0.706, train_wall=18, gb_free=19.5, wall=3037
2023-06-29 18:32:37 | INFO | train_inner | epoch 028:    488 / 556 loss=4.388, nll_loss=2.689, ppl=6.45, wps=73119.3, ups=5.35, wpb=13670.9, bsz=677.8, num_updates=15500, lr=0.000508001, gnorm=0.698, train_wall=18, gb_free=19.1, wall=3056
2023-06-29 18:32:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:32:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:32:49 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:32:50 | INFO | valid | epoch 028 | valid on 'valid' subset | loss 5.601 | nll_loss 3.99 | ppl 15.89 | wps 214142 | wpb 9430 | bsz 473.9 | num_updates 15568 | best_loss 5.524
2023-06-29 18:32:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 15568 updates
2023-06-29 18:32:50 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint28.pt
2023-06-29 18:32:52 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint28.pt
2023-06-29 18:32:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint28.pt (epoch 28 @ 15568 updates, score 5.601) (writing took 2.9551300518214703 seconds)
2023-06-29 18:32:53 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2023-06-29 18:32:53 | INFO | train | epoch 028 | loss 4.323 | nll_loss 2.613 | ppl 6.12 | wps 69647.6 | ups 5.14 | wpb 13556 | bsz 681.8 | num_updates 15568 | lr 0.00050689 | gnorm 0.702 | train_wall 103 | gb_free 19.1 | wall 3073
2023-06-29 18:32:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:32:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:32:53 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:32:53 | INFO | fairseq.trainer | begin training epoch 29
2023-06-29 18:32:53 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:33:00 | INFO | train_inner | epoch 029:     32 / 556 loss=4.339, nll_loss=2.632, ppl=6.2, wps=58878.1, ups=4.36, wpb=13518.2, bsz=686.6, num_updates=15600, lr=0.00050637, gnorm=0.713, train_wall=19, gb_free=19.2, wall=3079
2023-06-29 18:33:18 | INFO | train_inner | epoch 029:    132 / 556 loss=4.207, nll_loss=2.475, ppl=5.56, wps=73052.4, ups=5.35, wpb=13665.4, bsz=668.3, num_updates=15700, lr=0.000504754, gnorm=0.704, train_wall=18, gb_free=19, wall=3097
2023-06-29 18:33:37 | INFO | train_inner | epoch 029:    232 / 556 loss=4.266, nll_loss=2.545, ppl=5.84, wps=71235.3, ups=5.33, wpb=13359.1, bsz=682.3, num_updates=15800, lr=0.000503155, gnorm=0.699, train_wall=18, gb_free=19.5, wall=3116
2023-06-29 18:33:56 | INFO | train_inner | epoch 029:    332 / 556 loss=4.314, nll_loss=2.601, ppl=6.07, wps=72162.1, ups=5.31, wpb=13601.4, bsz=655.6, num_updates=15900, lr=0.00050157, gnorm=0.69, train_wall=19, gb_free=19.1, wall=3135
2023-06-29 18:34:15 | INFO | train_inner | epoch 029:    432 / 556 loss=4.32, nll_loss=2.611, ppl=6.11, wps=73186.9, ups=5.32, wpb=13747.7, bsz=712.4, num_updates=16000, lr=0.0005, gnorm=0.681, train_wall=19, gb_free=19.6, wall=3154
2023-06-29 18:34:34 | INFO | train_inner | epoch 029:    532 / 556 loss=4.367, nll_loss=2.667, ppl=6.35, wps=71722.9, ups=5.31, wpb=13509, bsz=694.8, num_updates=16100, lr=0.000498445, gnorm=0.695, train_wall=19, gb_free=19, wall=3173
2023-06-29 18:34:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:34:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:34:38 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:34:39 | INFO | valid | epoch 029 | valid on 'valid' subset | loss 5.622 | nll_loss 4.009 | ppl 16.1 | wps 208954 | wpb 9430 | bsz 473.9 | num_updates 16124 | best_loss 5.524
2023-06-29 18:34:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 16124 updates
2023-06-29 18:34:39 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint29.pt
2023-06-29 18:34:41 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint29.pt
2023-06-29 18:34:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint29.pt (epoch 29 @ 16124 updates, score 5.622) (writing took 2.2941385209560394 seconds)
2023-06-29 18:34:41 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2023-06-29 18:34:41 | INFO | train | epoch 029 | loss 4.292 | nll_loss 2.576 | ppl 5.96 | wps 69745.7 | ups 5.14 | wpb 13556 | bsz 681.8 | num_updates 16124 | lr 0.000498074 | gnorm 0.693 | train_wall 103 | gb_free 19.8 | wall 3181
2023-06-29 18:34:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:34:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:34:42 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:34:42 | INFO | fairseq.trainer | begin training epoch 30
2023-06-29 18:34:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:34:56 | INFO | train_inner | epoch 030:     76 / 556 loss=4.193, nll_loss=2.461, ppl=5.51, wps=60597.2, ups=4.45, wpb=13605.8, bsz=707.3, num_updates=16200, lr=0.000496904, gnorm=0.678, train_wall=19, gb_free=19.5, wall=3195
2023-06-29 18:35:15 | INFO | train_inner | epoch 030:    176 / 556 loss=4.217, nll_loss=2.488, ppl=5.61, wps=71469.6, ups=5.33, wpb=13408.9, bsz=697.7, num_updates=16300, lr=0.000495377, gnorm=0.7, train_wall=18, gb_free=19.2, wall=3214
2023-06-29 18:35:34 | INFO | train_inner | epoch 030:    276 / 556 loss=4.235, nll_loss=2.51, ppl=5.7, wps=72756.4, ups=5.3, wpb=13732, bsz=678.7, num_updates=16400, lr=0.000493865, gnorm=0.69, train_wall=19, gb_free=19.1, wall=3233
2023-06-29 18:35:53 | INFO | train_inner | epoch 030:    376 / 556 loss=4.302, nll_loss=2.588, ppl=6.01, wps=70736.4, ups=5.27, wpb=13420.6, bsz=670.3, num_updates=16500, lr=0.000492366, gnorm=0.707, train_wall=19, gb_free=19.3, wall=3252
2023-06-29 18:36:11 | INFO | train_inner | epoch 030:    476 / 556 loss=4.326, nll_loss=2.617, ppl=6.13, wps=71959.9, ups=5.31, wpb=13550.2, bsz=694.6, num_updates=16600, lr=0.000490881, gnorm=0.703, train_wall=19, gb_free=19.9, wall=3271
2023-06-29 18:36:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:36:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:36:26 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:36:27 | INFO | valid | epoch 030 | valid on 'valid' subset | loss 5.624 | nll_loss 4.009 | ppl 16.11 | wps 215394 | wpb 9430 | bsz 473.9 | num_updates 16680 | best_loss 5.524
2023-06-29 18:36:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 16680 updates
2023-06-29 18:36:27 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint30.pt
2023-06-29 18:36:29 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint30.pt
2023-06-29 18:36:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint30.pt (epoch 30 @ 16680 updates, score 5.624) (writing took 2.6905024237930775 seconds)
2023-06-29 18:36:30 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2023-06-29 18:36:30 | INFO | train | epoch 030 | loss 4.263 | nll_loss 2.543 | ppl 5.83 | wps 69348.6 | ups 5.12 | wpb 13556 | bsz 681.8 | num_updates 16680 | lr 0.000489702 | gnorm 0.694 | train_wall 103 | gb_free 19.2 | wall 3289
2023-06-29 18:36:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:36:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:36:30 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:36:30 | INFO | fairseq.trainer | begin training epoch 31
2023-06-29 18:36:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:36:34 | INFO | train_inner | epoch 031:     20 / 556 loss=4.308, nll_loss=2.595, ppl=6.04, wps=59938, ups=4.43, wpb=13530, bsz=642.3, num_updates=16700, lr=0.000489409, gnorm=0.688, train_wall=18, gb_free=19.5, wall=3293
2023-06-29 18:36:53 | INFO | train_inner | epoch 031:    120 / 556 loss=4.141, nll_loss=2.398, ppl=5.27, wps=71114.2, ups=5.27, wpb=13492.5, bsz=676.8, num_updates=16800, lr=0.00048795, gnorm=0.693, train_wall=19, gb_free=19.6, wall=3312
2023-06-29 18:37:12 | INFO | train_inner | epoch 031:    220 / 556 loss=4.209, nll_loss=2.479, ppl=5.57, wps=71869.1, ups=5.3, wpb=13550.1, bsz=676.8, num_updates=16900, lr=0.000486504, gnorm=0.706, train_wall=19, gb_free=19.1, wall=3331
2023-06-29 18:37:31 | INFO | train_inner | epoch 031:    320 / 556 loss=4.249, nll_loss=2.526, ppl=5.76, wps=70955.3, ups=5.27, wpb=13457.1, bsz=672.5, num_updates=17000, lr=0.000485071, gnorm=0.728, train_wall=19, gb_free=19.4, wall=3350
2023-06-29 18:37:50 | INFO | train_inner | epoch 031:    420 / 556 loss=4.28, nll_loss=2.562, ppl=5.91, wps=72634.2, ups=5.31, wpb=13674.4, bsz=662.6, num_updates=17100, lr=0.000483651, gnorm=0.707, train_wall=19, gb_free=19.4, wall=3369
2023-06-29 18:38:09 | INFO | train_inner | epoch 031:    520 / 556 loss=4.297, nll_loss=2.585, ppl=6, wps=71590.3, ups=5.28, wpb=13560.3, bsz=710, num_updates=17200, lr=0.000482243, gnorm=0.707, train_wall=19, gb_free=18.9, wall=3388
2023-06-29 18:38:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:38:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:38:15 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:38:16 | INFO | valid | epoch 031 | valid on 'valid' subset | loss 5.641 | nll_loss 4.02 | ppl 16.23 | wps 214883 | wpb 9430 | bsz 473.9 | num_updates 17236 | best_loss 5.524
2023-06-29 18:38:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 17236 updates
2023-06-29 18:38:16 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint31.pt
2023-06-29 18:38:18 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint31.pt
2023-06-29 18:38:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint31.pt (epoch 31 @ 17236 updates, score 5.641) (writing took 2.547399926930666 seconds)
2023-06-29 18:38:19 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2023-06-29 18:38:19 | INFO | train | epoch 031 | loss 4.235 | nll_loss 2.51 | ppl 5.7 | wps 69325.7 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 17236 | lr 0.000481739 | gnorm 0.705 | train_wall 103 | gb_free 19 | wall 3398
2023-06-29 18:38:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:38:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:38:19 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:38:19 | INFO | fairseq.trainer | begin training epoch 32
2023-06-29 18:38:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:38:31 | INFO | train_inner | epoch 032:     64 / 556 loss=4.177, nll_loss=2.443, ppl=5.44, wps=60246.1, ups=4.43, wpb=13597.3, bsz=698.8, num_updates=17300, lr=0.000480847, gnorm=0.695, train_wall=19, gb_free=19.2, wall=3410
2023-06-29 18:38:50 | INFO | train_inner | epoch 032:    164 / 556 loss=4.138, nll_loss=2.396, ppl=5.26, wps=71577.6, ups=5.28, wpb=13545.1, bsz=700.4, num_updates=17400, lr=0.000479463, gnorm=0.682, train_wall=19, gb_free=19, wall=3429
2023-06-29 18:39:09 | INFO | train_inner | epoch 032:    264 / 556 loss=4.183, nll_loss=2.449, ppl=5.46, wps=72572.4, ups=5.3, wpb=13690.8, bsz=690.1, num_updates=17500, lr=0.000478091, gnorm=0.693, train_wall=19, gb_free=19.5, wall=3448
2023-06-29 18:39:28 | INFO | train_inner | epoch 032:    364 / 556 loss=4.235, nll_loss=2.509, ppl=5.69, wps=71411.4, ups=5.27, wpb=13550.8, bsz=656.2, num_updates=17600, lr=0.000476731, gnorm=0.738, train_wall=19, gb_free=19.6, wall=3467
2023-06-29 18:39:47 | INFO | train_inner | epoch 032:    464 / 556 loss=4.266, nll_loss=2.546, ppl=5.84, wps=71822.2, ups=5.31, wpb=13517.6, bsz=649, num_updates=17700, lr=0.000475383, gnorm=0.722, train_wall=19, gb_free=19.3, wall=3486
2023-06-29 18:40:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:40:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:40:04 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:40:05 | INFO | valid | epoch 032 | valid on 'valid' subset | loss 5.658 | nll_loss 4.045 | ppl 16.51 | wps 214933 | wpb 9430 | bsz 473.9 | num_updates 17792 | best_loss 5.524
2023-06-29 18:40:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 17792 updates
2023-06-29 18:40:05 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint32.pt
2023-06-29 18:40:07 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint32.pt
2023-06-29 18:40:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint32.pt (epoch 32 @ 17792 updates, score 5.658) (writing took 2.8002520352602005 seconds)
2023-06-29 18:40:08 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2023-06-29 18:40:08 | INFO | train | epoch 032 | loss 4.211 | nll_loss 2.481 | ppl 5.58 | wps 69198.9 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 17792 | lr 0.000474152 | gnorm 0.712 | train_wall 103 | gb_free 18.9 | wall 3507
2023-06-29 18:40:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:40:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:40:08 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:40:08 | INFO | fairseq.trainer | begin training epoch 33
2023-06-29 18:40:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:40:09 | INFO | train_inner | epoch 033:      8 / 556 loss=4.28, nll_loss=2.565, ppl=5.92, wps=59603.6, ups=4.4, wpb=13548, bsz=711.8, num_updates=17800, lr=0.000474045, gnorm=0.72, train_wall=18, gb_free=19.1, wall=3509
2023-06-29 18:40:28 | INFO | train_inner | epoch 033:    108 / 556 loss=4.084, nll_loss=2.332, ppl=5.03, wps=72150.2, ups=5.32, wpb=13567.3, bsz=653, num_updates=17900, lr=0.000472719, gnorm=0.695, train_wall=19, gb_free=19.1, wall=3527
2023-06-29 18:40:47 | INFO | train_inner | epoch 033:    208 / 556 loss=4.142, nll_loss=2.4, ppl=5.28, wps=71744.5, ups=5.33, wpb=13471.9, bsz=682.1, num_updates=18000, lr=0.000471405, gnorm=0.723, train_wall=19, gb_free=18.8, wall=3546
2023-06-29 18:41:06 | INFO | train_inner | epoch 033:    308 / 556 loss=4.184, nll_loss=2.451, ppl=5.47, wps=70882.2, ups=5.23, wpb=13542.1, bsz=713.4, num_updates=18100, lr=0.0004701, gnorm=0.715, train_wall=19, gb_free=19.3, wall=3565
2023-06-29 18:41:25 | INFO | train_inner | epoch 033:    408 / 556 loss=4.232, nll_loss=2.506, ppl=5.68, wps=71818.9, ups=5.3, wpb=13561.2, bsz=662, num_updates=18200, lr=0.000468807, gnorm=0.719, train_wall=19, gb_free=19.1, wall=3584
2023-06-29 18:41:44 | INFO | train_inner | epoch 033:    508 / 556 loss=4.252, nll_loss=2.53, ppl=5.78, wps=71983.9, ups=5.31, wpb=13548.9, bsz=688.9, num_updates=18300, lr=0.000467525, gnorm=0.718, train_wall=19, gb_free=19, wall=3603
2023-06-29 18:41:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:41:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:41:53 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:41:54 | INFO | valid | epoch 033 | valid on 'valid' subset | loss 5.658 | nll_loss 4.045 | ppl 16.51 | wps 212267 | wpb 9430 | bsz 473.9 | num_updates 18348 | best_loss 5.524
2023-06-29 18:41:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 18348 updates
2023-06-29 18:41:54 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint33.pt
2023-06-29 18:41:55 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint33.pt
2023-06-29 18:41:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint33.pt (epoch 33 @ 18348 updates, score 5.658) (writing took 2.8350543044507504 seconds)
2023-06-29 18:41:57 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2023-06-29 18:41:57 | INFO | train | epoch 033 | loss 4.185 | nll_loss 2.452 | ppl 5.47 | wps 69111.9 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 18348 | lr 0.000466913 | gnorm 0.716 | train_wall 104 | gb_free 18.9 | wall 3616
2023-06-29 18:41:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:41:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:41:57 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:41:57 | INFO | fairseq.trainer | begin training epoch 34
2023-06-29 18:41:57 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:42:07 | INFO | train_inner | epoch 034:     52 / 556 loss=4.15, nll_loss=2.411, ppl=5.32, wps=59324.8, ups=4.35, wpb=13636.2, bsz=687.8, num_updates=18400, lr=0.000466252, gnorm=0.706, train_wall=19, gb_free=19.9, wall=3626
2023-06-29 18:42:26 | INFO | train_inner | epoch 034:    152 / 556 loss=4.087, nll_loss=2.336, ppl=5.05, wps=71824.8, ups=5.27, wpb=13629.8, bsz=694.4, num_updates=18500, lr=0.000464991, gnorm=0.705, train_wall=19, gb_free=19.4, wall=3645
2023-06-29 18:42:45 | INFO | train_inner | epoch 034:    252 / 556 loss=4.158, nll_loss=2.419, ppl=5.35, wps=72128.6, ups=5.33, wpb=13530.5, bsz=660.5, num_updates=18600, lr=0.000463739, gnorm=0.714, train_wall=18, gb_free=19.4, wall=3664
2023-06-29 18:43:03 | INFO | train_inner | epoch 034:    352 / 556 loss=4.176, nll_loss=2.441, ppl=5.43, wps=72056.4, ups=5.3, wpb=13597.8, bsz=679, num_updates=18700, lr=0.000462497, gnorm=0.722, train_wall=19, gb_free=19.4, wall=3683
2023-06-29 18:43:22 | INFO | train_inner | epoch 034:    452 / 556 loss=4.207, nll_loss=2.478, ppl=5.57, wps=70922.5, ups=5.25, wpb=13512.4, bsz=698.3, num_updates=18800, lr=0.000461266, gnorm=0.712, train_wall=19, gb_free=19, wall=3702
2023-06-29 18:43:41 | INFO | train_inner | epoch 034:    552 / 556 loss=4.231, nll_loss=2.507, ppl=5.68, wps=71354.6, ups=5.31, wpb=13448.9, bsz=674.2, num_updates=18900, lr=0.000460044, gnorm=0.714, train_wall=19, gb_free=19.2, wall=3720
2023-06-29 18:43:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:43:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:43:42 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:43:43 | INFO | valid | epoch 034 | valid on 'valid' subset | loss 5.677 | nll_loss 4.06 | ppl 16.68 | wps 212701 | wpb 9430 | bsz 473.9 | num_updates 18904 | best_loss 5.524
2023-06-29 18:43:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 18904 updates
2023-06-29 18:43:43 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint34.pt
2023-06-29 18:43:45 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint34.pt
2023-06-29 18:43:46 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint34.pt (epoch 34 @ 18904 updates, score 5.677) (writing took 2.757661208510399 seconds)
2023-06-29 18:43:46 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2023-06-29 18:43:46 | INFO | train | epoch 034 | loss 4.159 | nll_loss 2.421 | ppl 5.36 | wps 69102.7 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 18904 | lr 0.000459995 | gnorm 0.709 | train_wall 104 | gb_free 19.1 | wall 3725
2023-06-29 18:43:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:43:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:43:46 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:43:46 | INFO | fairseq.trainer | begin training epoch 35
2023-06-29 18:43:46 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:44:04 | INFO | train_inner | epoch 035:     96 / 556 loss=4.042, nll_loss=2.284, ppl=4.87, wps=59433.9, ups=4.37, wpb=13606.1, bsz=685.8, num_updates=19000, lr=0.000458831, gnorm=0.679, train_wall=19, gb_free=19.3, wall=3743
2023-06-29 18:44:23 | INFO | train_inner | epoch 035:    196 / 556 loss=4.099, nll_loss=2.349, ppl=5.1, wps=71938.9, ups=5.31, wpb=13559.6, bsz=682.1, num_updates=19100, lr=0.000457629, gnorm=0.706, train_wall=19, gb_free=19.3, wall=3762
2023-06-29 18:44:42 | INFO | train_inner | epoch 035:    296 / 556 loss=4.142, nll_loss=2.402, ppl=5.28, wps=70938.2, ups=5.28, wpb=13439.2, bsz=688.6, num_updates=19200, lr=0.000456435, gnorm=0.721, train_wall=19, gb_free=18.8, wall=3781
2023-06-29 18:45:01 | INFO | train_inner | epoch 035:    396 / 556 loss=4.184, nll_loss=2.449, ppl=5.46, wps=71708.4, ups=5.31, wpb=13494.3, bsz=642, num_updates=19300, lr=0.000455251, gnorm=0.728, train_wall=19, gb_free=19.5, wall=3800
2023-06-29 18:45:20 | INFO | train_inner | epoch 035:    496 / 556 loss=4.186, nll_loss=2.455, ppl=5.48, wps=71674.9, ups=5.23, wpb=13692.8, bsz=698.6, num_updates=19400, lr=0.000454077, gnorm=0.707, train_wall=19, gb_free=19.2, wall=3819
2023-06-29 18:45:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:45:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:45:31 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:45:32 | INFO | valid | epoch 035 | valid on 'valid' subset | loss 5.688 | nll_loss 4.074 | ppl 16.85 | wps 212917 | wpb 9430 | bsz 473.9 | num_updates 19460 | best_loss 5.524
2023-06-29 18:45:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 19460 updates
2023-06-29 18:45:32 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint35.pt
2023-06-29 18:45:34 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint35.pt
2023-06-29 18:45:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint35.pt (epoch 35 @ 19460 updates, score 5.688) (writing took 2.6508395820856094 seconds)
2023-06-29 18:45:35 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2023-06-29 18:45:35 | INFO | train | epoch 035 | loss 4.137 | nll_loss 2.395 | ppl 5.26 | wps 69184 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 19460 | lr 0.000453376 | gnorm 0.712 | train_wall 104 | gb_free 19.5 | wall 3834
2023-06-29 18:45:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:45:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:45:35 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:45:35 | INFO | fairseq.trainer | begin training epoch 36
2023-06-29 18:45:35 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:45:42 | INFO | train_inner | epoch 036:     40 / 556 loss=4.128, nll_loss=2.387, ppl=5.23, wps=59696.7, ups=4.44, wpb=13437.1, bsz=695.8, num_updates=19500, lr=0.000452911, gnorm=0.737, train_wall=18, gb_free=19.5, wall=3842
2023-06-29 18:46:01 | INFO | train_inner | epoch 036:    140 / 556 loss=4.025, nll_loss=2.265, ppl=4.81, wps=73075.9, ups=5.32, wpb=13741, bsz=709.2, num_updates=19600, lr=0.000451754, gnorm=0.682, train_wall=19, gb_free=19, wall=3860
2023-06-29 18:46:20 | INFO | train_inner | epoch 036:    240 / 556 loss=4.106, nll_loss=2.356, ppl=5.12, wps=71385.2, ups=5.36, wpb=13320.3, bsz=620.1, num_updates=19700, lr=0.000450606, gnorm=0.716, train_wall=18, gb_free=19, wall=3879
2023-06-29 18:46:39 | INFO | train_inner | epoch 036:    340 / 556 loss=4.13, nll_loss=2.389, ppl=5.24, wps=72970, ups=5.31, wpb=13754.7, bsz=704.8, num_updates=19800, lr=0.000449467, gnorm=0.739, train_wall=19, gb_free=19.2, wall=3898
2023-06-29 18:46:58 | INFO | train_inner | epoch 036:    440 / 556 loss=4.156, nll_loss=2.419, ppl=5.35, wps=72623, ups=5.32, wpb=13639.7, bsz=683.4, num_updates=19900, lr=0.000448336, gnorm=0.74, train_wall=19, gb_free=19.4, wall=3917
2023-06-29 18:47:16 | INFO | train_inner | epoch 036:    540 / 556 loss=4.18, nll_loss=2.448, ppl=5.46, wps=71437.5, ups=5.28, wpb=13533.5, bsz=685.9, num_updates=20000, lr=0.000447214, gnorm=0.715, train_wall=19, gb_free=19.2, wall=3936
2023-06-29 18:47:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:47:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:47:19 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:47:20 | INFO | valid | epoch 036 | valid on 'valid' subset | loss 5.705 | nll_loss 4.098 | ppl 17.13 | wps 211425 | wpb 9430 | bsz 473.9 | num_updates 20016 | best_loss 5.524
2023-06-29 18:47:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 20016 updates
2023-06-29 18:47:20 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint36.pt
2023-06-29 18:47:22 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint36.pt
2023-06-29 18:47:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint36.pt (epoch 36 @ 20016 updates, score 5.705) (writing took 2.844009503722191 seconds)
2023-06-29 18:47:23 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2023-06-29 18:47:23 | INFO | train | epoch 036 | loss 4.115 | nll_loss 2.371 | ppl 5.17 | wps 69457.6 | ups 5.12 | wpb 13556 | bsz 681.8 | num_updates 20016 | lr 0.000447035 | gnorm 0.72 | train_wall 103 | gb_free 20 | wall 3943
2023-06-29 18:47:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:47:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:47:23 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:47:23 | INFO | fairseq.trainer | begin training epoch 37
2023-06-29 18:47:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:47:39 | INFO | train_inner | epoch 037:     84 / 556 loss=4.034, nll_loss=2.275, ppl=4.84, wps=58663.7, ups=4.38, wpb=13404.2, bsz=682.4, num_updates=20100, lr=0.0004461, gnorm=0.697, train_wall=19, gb_free=19, wall=3958
2023-06-29 18:47:58 | INFO | train_inner | epoch 037:    184 / 556 loss=4.038, nll_loss=2.28, ppl=4.86, wps=72445.4, ups=5.3, wpb=13660.3, bsz=702, num_updates=20200, lr=0.000444994, gnorm=0.715, train_wall=19, gb_free=18.9, wall=3977
2023-06-29 18:48:17 | INFO | train_inner | epoch 037:    284 / 556 loss=4.066, nll_loss=2.312, ppl=4.97, wps=72025, ups=5.3, wpb=13580.5, bsz=670.2, num_updates=20300, lr=0.000443897, gnorm=0.699, train_wall=19, gb_free=19, wall=3996
2023-06-29 18:48:36 | INFO | train_inner | epoch 037:    384 / 556 loss=4.114, nll_loss=2.371, ppl=5.17, wps=72656.8, ups=5.3, wpb=13720.1, bsz=701.3, num_updates=20400, lr=0.000442807, gnorm=0.712, train_wall=19, gb_free=19.4, wall=4015
2023-06-29 18:48:55 | INFO | train_inner | epoch 037:    484 / 556 loss=4.172, nll_loss=2.436, ppl=5.41, wps=70581.9, ups=5.31, wpb=13283.2, bsz=647.8, num_updates=20500, lr=0.000441726, gnorm=0.737, train_wall=19, gb_free=20.1, wall=4034
2023-06-29 18:49:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:49:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:49:08 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:49:09 | INFO | valid | epoch 037 | valid on 'valid' subset | loss 5.708 | nll_loss 4.11 | ppl 17.27 | wps 197431 | wpb 9430 | bsz 473.9 | num_updates 20572 | best_loss 5.524
2023-06-29 18:49:09 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 20572 updates
2023-06-29 18:49:09 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint37.pt
2023-06-29 18:49:11 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint37.pt
2023-06-29 18:49:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint37.pt (epoch 37 @ 20572 updates, score 5.708) (writing took 2.800845991820097 seconds)
2023-06-29 18:49:12 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2023-06-29 18:49:12 | INFO | train | epoch 037 | loss 4.092 | nll_loss 2.344 | ppl 5.08 | wps 69264.7 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 20572 | lr 0.000440952 | gnorm 0.713 | train_wall 103 | gb_free 19.3 | wall 4051
2023-06-29 18:49:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:49:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:49:12 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:49:12 | INFO | fairseq.trainer | begin training epoch 38
2023-06-29 18:49:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:49:18 | INFO | train_inner | epoch 038:     28 / 556 loss=4.107, nll_loss=2.363, ppl=5.14, wps=59183.2, ups=4.36, wpb=13558.9, bsz=700.3, num_updates=20600, lr=0.000440653, gnorm=0.71, train_wall=19, gb_free=18.9, wall=4057
2023-06-29 18:49:37 | INFO | train_inner | epoch 038:    128 / 556 loss=3.984, nll_loss=2.216, ppl=4.65, wps=72505.1, ups=5.27, wpb=13767.2, bsz=688.3, num_updates=20700, lr=0.000439587, gnorm=0.682, train_wall=19, gb_free=19.6, wall=4076
2023-06-29 18:49:55 | INFO | train_inner | epoch 038:    228 / 556 loss=4.05, nll_loss=2.293, ppl=4.9, wps=71987.7, ups=5.34, wpb=13480.6, bsz=654.9, num_updates=20800, lr=0.000438529, gnorm=0.727, train_wall=18, gb_free=18.9, wall=4095
2023-06-29 18:50:14 | INFO | train_inner | epoch 038:    328 / 556 loss=4.089, nll_loss=2.34, ppl=5.06, wps=71617.5, ups=5.34, wpb=13400.7, bsz=685.8, num_updates=20900, lr=0.000437479, gnorm=0.736, train_wall=18, gb_free=19.2, wall=4113
2023-06-29 18:50:33 | INFO | train_inner | epoch 038:    428 / 556 loss=4.118, nll_loss=2.374, ppl=5.18, wps=72135.7, ups=5.33, wpb=13532.2, bsz=673.3, num_updates=21000, lr=0.000436436, gnorm=0.725, train_wall=18, gb_free=19.3, wall=4132
2023-06-29 18:50:52 | INFO | train_inner | epoch 038:    528 / 556 loss=4.131, nll_loss=2.393, ppl=5.25, wps=73123.2, ups=5.34, wpb=13696.9, bsz=704.2, num_updates=21100, lr=0.0004354, gnorm=0.731, train_wall=18, gb_free=18.9, wall=4151
2023-06-29 18:50:57 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:50:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:50:57 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:50:58 | INFO | valid | epoch 038 | valid on 'valid' subset | loss 5.711 | nll_loss 4.107 | ppl 17.24 | wps 212319 | wpb 9430 | bsz 473.9 | num_updates 21128 | best_loss 5.524
2023-06-29 18:50:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 21128 updates
2023-06-29 18:50:58 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint38.pt
2023-06-29 18:50:59 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint38.pt
2023-06-29 18:51:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint38.pt (epoch 38 @ 21128 updates, score 5.711) (writing took 2.972953826189041 seconds)
2023-06-29 18:51:01 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2023-06-29 18:51:01 | INFO | train | epoch 038 | loss 4.073 | nll_loss 2.321 | ppl 5 | wps 69305.5 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 21128 | lr 0.000435112 | gnorm 0.719 | train_wall 103 | gb_free 19.1 | wall 4160
2023-06-29 18:51:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:51:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:51:01 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:51:01 | INFO | fairseq.trainer | begin training epoch 39
2023-06-29 18:51:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:51:15 | INFO | train_inner | epoch 039:     72 / 556 loss=4.009, nll_loss=2.245, ppl=4.74, wps=58381.9, ups=4.33, wpb=13489.5, bsz=650.1, num_updates=21200, lr=0.000434372, gnorm=0.718, train_wall=19, gb_free=19.5, wall=4174
2023-06-29 18:51:34 | INFO | train_inner | epoch 039:    172 / 556 loss=3.999, nll_loss=2.234, ppl=4.7, wps=71037.6, ups=5.28, wpb=13458, bsz=684.5, num_updates=21300, lr=0.000433351, gnorm=0.712, train_wall=19, gb_free=19.3, wall=4193
2023-06-29 18:51:52 | INFO | train_inner | epoch 039:    272 / 556 loss=4.049, nll_loss=2.294, ppl=4.9, wps=71197.8, ups=5.32, wpb=13372.2, bsz=699.9, num_updates=21400, lr=0.000432338, gnorm=0.731, train_wall=19, gb_free=19.5, wall=4212
2023-06-29 18:52:11 | INFO | train_inner | epoch 039:    372 / 556 loss=4.081, nll_loss=2.33, ppl=5.03, wps=71817.4, ups=5.3, wpb=13560.5, bsz=676.2, num_updates=21500, lr=0.000431331, gnorm=0.735, train_wall=19, gb_free=19.3, wall=4230
2023-06-29 18:52:30 | INFO | train_inner | epoch 039:    472 / 556 loss=4.082, nll_loss=2.334, ppl=5.04, wps=73769.4, ups=5.31, wpb=13901.4, bsz=700, num_updates=21600, lr=0.000430331, gnorm=0.703, train_wall=19, gb_free=19, wall=4249
2023-06-29 18:52:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:52:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:52:46 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:52:47 | INFO | valid | epoch 039 | valid on 'valid' subset | loss 5.727 | nll_loss 4.116 | ppl 17.34 | wps 214793 | wpb 9430 | bsz 473.9 | num_updates 21684 | best_loss 5.524
2023-06-29 18:52:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 21684 updates
2023-06-29 18:52:47 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint39.pt
2023-06-29 18:52:48 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint39.pt
2023-06-29 18:52:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint39.pt (epoch 39 @ 21684 updates, score 5.727) (writing took 2.7998511008918285 seconds)
2023-06-29 18:52:50 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2023-06-29 18:52:50 | INFO | train | epoch 039 | loss 4.053 | nll_loss 2.297 | ppl 4.92 | wps 69309.6 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 21684 | lr 0.000429497 | gnorm 0.723 | train_wall 103 | gb_free 19.1 | wall 4269
2023-06-29 18:52:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:52:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:52:50 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:52:50 | INFO | fairseq.trainer | begin training epoch 40
2023-06-29 18:52:50 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:52:53 | INFO | train_inner | epoch 040:     16 / 556 loss=4.111, nll_loss=2.367, ppl=5.16, wps=59536.1, ups=4.42, wpb=13484, bsz=666.8, num_updates=21700, lr=0.000429339, gnorm=0.734, train_wall=18, gb_free=18.9, wall=4272
2023-06-29 18:53:12 | INFO | train_inner | epoch 040:    116 / 556 loss=3.974, nll_loss=2.202, ppl=4.6, wps=70491.9, ups=5.29, wpb=13316.9, bsz=660.4, num_updates=21800, lr=0.000428353, gnorm=0.758, train_wall=19, gb_free=19.1, wall=4291
2023-06-29 18:53:31 | INFO | train_inner | epoch 040:    216 / 556 loss=3.99, nll_loss=2.223, ppl=4.67, wps=72553.5, ups=5.27, wpb=13771.8, bsz=677.3, num_updates=21900, lr=0.000427374, gnorm=0.71, train_wall=19, gb_free=18.9, wall=4310
2023-06-29 18:53:50 | INFO | train_inner | epoch 040:    316 / 556 loss=4.02, nll_loss=2.26, ppl=4.79, wps=72464.2, ups=5.25, wpb=13789.7, bsz=692.3, num_updates=22000, lr=0.000426401, gnorm=0.731, train_wall=19, gb_free=18.9, wall=4329
2023-06-29 18:54:09 | INFO | train_inner | epoch 040:    416 / 556 loss=4.07, nll_loss=2.318, ppl=4.99, wps=71076.6, ups=5.31, wpb=13379.6, bsz=663.9, num_updates=22100, lr=0.000425436, gnorm=0.747, train_wall=19, gb_free=19.1, wall=4348
2023-06-29 18:54:27 | INFO | train_inner | epoch 040:    516 / 556 loss=4.086, nll_loss=2.339, ppl=5.06, wps=72600, ups=5.3, wpb=13701.8, bsz=712.6, num_updates=22200, lr=0.000424476, gnorm=0.728, train_wall=19, gb_free=19.4, wall=4367
2023-06-29 18:54:35 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:54:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:54:35 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:54:36 | INFO | valid | epoch 040 | valid on 'valid' subset | loss 5.743 | nll_loss 4.137 | ppl 17.6 | wps 209420 | wpb 9430 | bsz 473.9 | num_updates 22240 | best_loss 5.524
2023-06-29 18:54:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 22240 updates
2023-06-29 18:54:36 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint40.pt
2023-06-29 18:54:37 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint40.pt
2023-06-29 18:54:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint40.pt (epoch 40 @ 22240 updates, score 5.743) (writing took 2.6273648776113987 seconds)
2023-06-29 18:54:39 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2023-06-29 18:54:39 | INFO | train | epoch 040 | loss 4.032 | nll_loss 2.273 | ppl 4.83 | wps 69167.2 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 22240 | lr 0.000424094 | gnorm 0.734 | train_wall 104 | gb_free 19.8 | wall 4378
2023-06-29 18:54:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:54:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:54:39 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:54:39 | INFO | fairseq.trainer | begin training epoch 41
2023-06-29 18:54:39 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:54:50 | INFO | train_inner | epoch 041:     60 / 556 loss=3.976, nll_loss=2.21, ppl=4.63, wps=59402.4, ups=4.39, wpb=13516.3, bsz=710.2, num_updates=22300, lr=0.000423524, gnorm=0.701, train_wall=19, gb_free=19.2, wall=4389
2023-06-29 18:55:09 | INFO | train_inner | epoch 041:    160 / 556 loss=3.969, nll_loss=2.198, ppl=4.59, wps=71312.4, ups=5.29, wpb=13471.7, bsz=665.8, num_updates=22400, lr=0.000422577, gnorm=0.73, train_wall=19, gb_free=19.1, wall=4408
2023-06-29 18:55:28 | INFO | train_inner | epoch 041:    260 / 556 loss=4.003, nll_loss=2.238, ppl=4.72, wps=70810.9, ups=5.29, wpb=13395.7, bsz=648.4, num_updates=22500, lr=0.000421637, gnorm=0.735, train_wall=19, gb_free=19.5, wall=4427
2023-06-29 18:55:47 | INFO | train_inner | epoch 041:    360 / 556 loss=4.02, nll_loss=2.263, ppl=4.8, wps=72494.8, ups=5.3, wpb=13686.8, bsz=763.2, num_updates=22600, lr=0.000420703, gnorm=0.709, train_wall=19, gb_free=18.9, wall=4446
2023-06-29 18:56:06 | INFO | train_inner | epoch 041:    460 / 556 loss=4.061, nll_loss=2.308, ppl=4.95, wps=72303.3, ups=5.32, wpb=13587.2, bsz=663.8, num_updates=22700, lr=0.000419775, gnorm=0.752, train_wall=19, gb_free=19.1, wall=4465
2023-06-29 18:56:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:56:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:56:24 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:56:25 | INFO | valid | epoch 041 | valid on 'valid' subset | loss 5.758 | nll_loss 4.159 | ppl 17.86 | wps 214189 | wpb 9430 | bsz 473.9 | num_updates 22796 | best_loss 5.524
2023-06-29 18:56:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 22796 updates
2023-06-29 18:56:25 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint41.pt
2023-06-29 18:56:26 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint41.pt
2023-06-29 18:56:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint41.pt (epoch 41 @ 22796 updates, score 5.758) (writing took 2.668136667460203 seconds)
2023-06-29 18:56:27 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2023-06-29 18:56:27 | INFO | train | epoch 041 | loss 4.014 | nll_loss 2.253 | ppl 4.77 | wps 69310 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 22796 | lr 0.000418891 | gnorm 0.728 | train_wall 103 | gb_free 19 | wall 4487
2023-06-29 18:56:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:56:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:56:28 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:56:28 | INFO | fairseq.trainer | begin training epoch 42
2023-06-29 18:56:28 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:56:28 | INFO | train_inner | epoch 042:      4 / 556 loss=4.087, nll_loss=2.339, ppl=5.06, wps=59631.2, ups=4.41, wpb=13530.3, bsz=646.5, num_updates=22800, lr=0.000418854, gnorm=0.746, train_wall=19, gb_free=19.6, wall=4487
2023-06-29 18:56:47 | INFO | train_inner | epoch 042:    104 / 556 loss=3.903, nll_loss=2.121, ppl=4.35, wps=72143.8, ups=5.33, wpb=13527.4, bsz=663.9, num_updates=22900, lr=0.000417938, gnorm=0.722, train_wall=18, gb_free=19.5, wall=4506
2023-06-29 18:57:06 | INFO | train_inner | epoch 042:    204 / 556 loss=3.972, nll_loss=2.201, ppl=4.6, wps=71925.7, ups=5.31, wpb=13551.3, bsz=646.7, num_updates=23000, lr=0.000417029, gnorm=0.729, train_wall=19, gb_free=18.9, wall=4525
2023-06-29 18:57:25 | INFO | train_inner | epoch 042:    304 / 556 loss=4, nll_loss=2.236, ppl=4.71, wps=71794.9, ups=5.31, wpb=13522.4, bsz=673.4, num_updates=23100, lr=0.000416125, gnorm=0.744, train_wall=19, gb_free=19.3, wall=4544
2023-06-29 18:57:44 | INFO | train_inner | epoch 042:    404 / 556 loss=4.013, nll_loss=2.253, ppl=4.77, wps=72344.7, ups=5.31, wpb=13623.6, bsz=694.6, num_updates=23200, lr=0.000415227, gnorm=0.732, train_wall=19, gb_free=19.3, wall=4563
2023-06-29 18:58:03 | INFO | train_inner | epoch 042:    504 / 556 loss=4.063, nll_loss=2.312, ppl=4.97, wps=71213.3, ups=5.28, wpb=13488, bsz=706.8, num_updates=23300, lr=0.000414335, gnorm=0.756, train_wall=19, gb_free=19.5, wall=4582
2023-06-29 18:58:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 18:58:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:58:12 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:58:13 | INFO | valid | epoch 042 | valid on 'valid' subset | loss 5.77 | nll_loss 4.162 | ppl 17.9 | wps 214773 | wpb 9430 | bsz 473.9 | num_updates 23352 | best_loss 5.524
2023-06-29 18:58:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 23352 updates
2023-06-29 18:58:13 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint42.pt
2023-06-29 18:58:15 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint42.pt
2023-06-29 18:58:16 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint42.pt (epoch 42 @ 23352 updates, score 5.77) (writing took 2.7291075363755226 seconds)
2023-06-29 18:58:16 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2023-06-29 18:58:16 | INFO | train | epoch 042 | loss 3.997 | nll_loss 2.233 | ppl 4.7 | wps 69359 | ups 5.12 | wpb 13556 | bsz 681.8 | num_updates 23352 | lr 0.000413874 | gnorm 0.734 | train_wall 103 | gb_free 19 | wall 4595
2023-06-29 18:58:16 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 18:58:16 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 18:58:16 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 18:58:16 | INFO | fairseq.trainer | begin training epoch 43
2023-06-29 18:58:16 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 18:58:25 | INFO | train_inner | epoch 043:     48 / 556 loss=3.974, nll_loss=2.207, ppl=4.62, wps=59876.7, ups=4.41, wpb=13587.1, bsz=705, num_updates=23400, lr=0.000413449, gnorm=0.719, train_wall=19, gb_free=19.2, wall=4604
2023-06-29 18:58:44 | INFO | train_inner | epoch 043:    148 / 556 loss=3.913, nll_loss=2.133, ppl=4.39, wps=71948.1, ups=5.3, wpb=13583, bsz=668.6, num_updates=23500, lr=0.000412568, gnorm=0.733, train_wall=19, gb_free=19.1, wall=4623
2023-06-29 18:59:03 | INFO | train_inner | epoch 043:    248 / 556 loss=3.956, nll_loss=2.186, ppl=4.55, wps=71955.6, ups=5.3, wpb=13584.8, bsz=713.9, num_updates=23600, lr=0.000411693, gnorm=0.71, train_wall=19, gb_free=19.7, wall=4642
2023-06-29 18:59:22 | INFO | train_inner | epoch 043:    348 / 556 loss=4.006, nll_loss=2.243, ppl=4.73, wps=70865.8, ups=5.29, wpb=13398.8, bsz=658.9, num_updates=23700, lr=0.000410824, gnorm=0.752, train_wall=19, gb_free=19.5, wall=4661
2023-06-29 18:59:41 | INFO | train_inner | epoch 043:    448 / 556 loss=4.014, nll_loss=2.255, ppl=4.77, wps=72417.2, ups=5.31, wpb=13650.1, bsz=704.8, num_updates=23800, lr=0.00040996, gnorm=0.736, train_wall=19, gb_free=20.1, wall=4680
2023-06-29 19:00:00 | INFO | train_inner | epoch 043:    548 / 556 loss=4.044, nll_loss=2.289, ppl=4.89, wps=71867.9, ups=5.26, wpb=13662.2, bsz=676.7, num_updates=23900, lr=0.000409101, gnorm=0.735, train_wall=19, gb_free=19.2, wall=4699
2023-06-29 19:00:01 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:00:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:00:01 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:00:02 | INFO | valid | epoch 043 | valid on 'valid' subset | loss 5.768 | nll_loss 4.165 | ppl 17.94 | wps 213158 | wpb 9430 | bsz 473.9 | num_updates 23908 | best_loss 5.524
2023-06-29 19:00:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 23908 updates
2023-06-29 19:00:02 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint43.pt
2023-06-29 19:00:04 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint43.pt
2023-06-29 19:00:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint43.pt (epoch 43 @ 23908 updates, score 5.768) (writing took 2.871502213180065 seconds)
2023-06-29 19:00:05 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2023-06-29 19:00:05 | INFO | train | epoch 043 | loss 3.979 | nll_loss 2.212 | ppl 4.63 | wps 69099.6 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 23908 | lr 0.000409033 | gnorm 0.734 | train_wall 103 | gb_free 19.1 | wall 4704
2023-06-29 19:00:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:00:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:00:05 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:00:05 | INFO | fairseq.trainer | begin training epoch 44
2023-06-29 19:00:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:00:23 | INFO | train_inner | epoch 044:     92 / 556 loss=3.88, nll_loss=2.096, ppl=4.28, wps=59103.5, ups=4.35, wpb=13595, bsz=698.4, num_updates=24000, lr=0.000408248, gnorm=0.714, train_wall=19, gb_free=18.9, wall=4722
2023-06-29 19:00:42 | INFO | train_inner | epoch 044:    192 / 556 loss=3.91, nll_loss=2.131, ppl=4.38, wps=71818.9, ups=5.32, wpb=13505.6, bsz=679.8, num_updates=24100, lr=0.0004074, gnorm=0.731, train_wall=19, gb_free=19.3, wall=4741
2023-06-29 19:01:00 | INFO | train_inner | epoch 044:    292 / 556 loss=3.962, nll_loss=2.191, ppl=4.57, wps=71605.1, ups=5.3, wpb=13499.1, bsz=658.6, num_updates=24200, lr=0.000406558, gnorm=0.763, train_wall=19, gb_free=18.9, wall=4760
2023-06-29 19:01:19 | INFO | train_inner | epoch 044:    392 / 556 loss=3.997, nll_loss=2.234, ppl=4.7, wps=71868.5, ups=5.29, wpb=13595.8, bsz=685.8, num_updates=24300, lr=0.00040572, gnorm=0.737, train_wall=19, gb_free=19.3, wall=4778
2023-06-29 19:01:38 | INFO | train_inner | epoch 044:    492 / 556 loss=4.03, nll_loss=2.273, ppl=4.83, wps=71518, ups=5.3, wpb=13505.7, bsz=683, num_updates=24400, lr=0.000404888, gnorm=0.736, train_wall=19, gb_free=19, wall=4797
2023-06-29 19:01:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:01:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:01:50 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:01:51 | INFO | valid | epoch 044 | valid on 'valid' subset | loss 5.783 | nll_loss 4.185 | ppl 18.19 | wps 211623 | wpb 9430 | bsz 473.9 | num_updates 24464 | best_loss 5.524
2023-06-29 19:01:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 24464 updates
2023-06-29 19:01:51 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint44.pt
2023-06-29 19:01:53 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint44.pt
2023-06-29 19:01:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint44.pt (epoch 44 @ 24464 updates, score 5.783) (writing took 2.3034089282155037 seconds)
2023-06-29 19:01:54 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2023-06-29 19:01:54 | INFO | train | epoch 044 | loss 3.962 | nll_loss 2.193 | ppl 4.57 | wps 69555.9 | ups 5.13 | wpb 13556 | bsz 681.8 | num_updates 24464 | lr 0.000404358 | gnorm 0.733 | train_wall 103 | gb_free 19.5 | wall 4813
2023-06-29 19:01:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:01:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:01:54 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:01:54 | INFO | fairseq.trainer | begin training epoch 45
2023-06-29 19:01:54 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:02:00 | INFO | train_inner | epoch 045:     36 / 556 loss=3.958, nll_loss=2.19, ppl=4.56, wps=60807.9, ups=4.49, wpb=13534.9, bsz=703.3, num_updates=24500, lr=0.000404061, gnorm=0.708, train_wall=18, gb_free=19.1, wall=4820
2023-06-29 19:02:19 | INFO | train_inner | epoch 045:    136 / 556 loss=3.88, nll_loss=2.095, ppl=4.27, wps=71965.6, ups=5.29, wpb=13612.9, bsz=681, num_updates=24600, lr=0.000403239, gnorm=0.708, train_wall=19, gb_free=19, wall=4839
2023-06-29 19:02:38 | INFO | train_inner | epoch 045:    236 / 556 loss=3.915, nll_loss=2.138, ppl=4.4, wps=71331, ups=5.27, wpb=13538.6, bsz=710.3, num_updates=24700, lr=0.000402422, gnorm=0.746, train_wall=19, gb_free=18.9, wall=4857
2023-06-29 19:02:57 | INFO | train_inner | epoch 045:    336 / 556 loss=3.95, nll_loss=2.178, ppl=4.52, wps=72352.2, ups=5.33, wpb=13569.6, bsz=666.2, num_updates=24800, lr=0.00040161, gnorm=0.749, train_wall=18, gb_free=19.1, wall=4876
2023-06-29 19:03:16 | INFO | train_inner | epoch 045:    436 / 556 loss=3.985, nll_loss=2.221, ppl=4.66, wps=72007.6, ups=5.31, wpb=13572.1, bsz=658.5, num_updates=24900, lr=0.000400802, gnorm=0.731, train_wall=19, gb_free=19.8, wall=4895
2023-06-29 19:03:35 | INFO | train_inner | epoch 045:    536 / 556 loss=4.024, nll_loss=2.266, ppl=4.81, wps=71765.7, ups=5.31, wpb=13527.3, bsz=678.2, num_updates=25000, lr=0.0004, gnorm=0.752, train_wall=19, gb_free=19.3, wall=4914
2023-06-29 19:03:39 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:03:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:03:39 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:03:40 | INFO | valid | epoch 045 | valid on 'valid' subset | loss 5.807 | nll_loss 4.201 | ppl 18.39 | wps 214726 | wpb 9430 | bsz 473.9 | num_updates 25020 | best_loss 5.524
2023-06-29 19:03:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 25020 updates
2023-06-29 19:03:40 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint45.pt
2023-06-29 19:03:41 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint45.pt
2023-06-29 19:03:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint45.pt (epoch 45 @ 25020 updates, score 5.807) (writing took 2.8000998832285404 seconds)
2023-06-29 19:03:42 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2023-06-29 19:03:42 | INFO | train | epoch 045 | loss 3.946 | nll_loss 2.174 | ppl 4.51 | wps 69207.2 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 25020 | lr 0.00039984 | gnorm 0.735 | train_wall 103 | gb_free 19 | wall 4922
2023-06-29 19:03:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:03:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:03:43 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:03:43 | INFO | fairseq.trainer | begin training epoch 46
2023-06-29 19:03:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:03:58 | INFO | train_inner | epoch 046:     80 / 556 loss=3.874, nll_loss=2.09, ppl=4.26, wps=59927.2, ups=4.38, wpb=13677.7, bsz=687.8, num_updates=25100, lr=0.000399202, gnorm=0.713, train_wall=19, gb_free=19.2, wall=4937
2023-06-29 19:04:17 | INFO | train_inner | epoch 046:    180 / 556 loss=3.878, nll_loss=2.094, ppl=4.27, wps=71554.8, ups=5.26, wpb=13591.9, bsz=687.4, num_updates=25200, lr=0.00039841, gnorm=0.723, train_wall=19, gb_free=19.2, wall=4956
2023-06-29 19:04:35 | INFO | train_inner | epoch 046:    280 / 556 loss=3.936, nll_loss=2.161, ppl=4.47, wps=71496.9, ups=5.3, wpb=13482.2, bsz=667.5, num_updates=25300, lr=0.000397621, gnorm=0.742, train_wall=19, gb_free=19.3, wall=4975
2023-06-29 19:04:54 | INFO | train_inner | epoch 046:    380 / 556 loss=3.953, nll_loss=2.183, ppl=4.54, wps=72512.9, ups=5.31, wpb=13647, bsz=690.1, num_updates=25400, lr=0.000396838, gnorm=0.729, train_wall=19, gb_free=19, wall=4993
2023-06-29 19:05:13 | INFO | train_inner | epoch 046:    480 / 556 loss=3.973, nll_loss=2.206, ppl=4.62, wps=71424.7, ups=5.31, wpb=13449.8, bsz=659, num_updates=25500, lr=0.000396059, gnorm=0.744, train_wall=19, gb_free=20.4, wall=5012
2023-06-29 19:05:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:05:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:05:28 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:05:29 | INFO | valid | epoch 046 | valid on 'valid' subset | loss 5.81 | nll_loss 4.209 | ppl 18.49 | wps 213212 | wpb 9430 | bsz 473.9 | num_updates 25576 | best_loss 5.524
2023-06-29 19:05:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 25576 updates
2023-06-29 19:05:29 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint46.pt
2023-06-29 19:05:30 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint46.pt
2023-06-29 19:05:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint46.pt (epoch 46 @ 25576 updates, score 5.81) (writing took 2.800192378461361 seconds)
2023-06-29 19:05:31 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2023-06-29 19:05:31 | INFO | train | epoch 046 | loss 3.93 | nll_loss 2.155 | ppl 4.45 | wps 69178.5 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 25576 | lr 0.00039547 | gnorm 0.732 | train_wall 103 | gb_free 19 | wall 5031
2023-06-29 19:05:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:05:31 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:05:31 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:05:31 | INFO | fairseq.trainer | begin training epoch 47
2023-06-29 19:05:31 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:05:36 | INFO | train_inner | epoch 047:     24 / 556 loss=3.958, nll_loss=2.188, ppl=4.56, wps=59377.8, ups=4.37, wpb=13602.5, bsz=674.4, num_updates=25600, lr=0.000395285, gnorm=0.734, train_wall=19, gb_free=19.4, wall=5035
2023-06-29 19:05:55 | INFO | train_inner | epoch 047:    124 / 556 loss=3.826, nll_loss=2.033, ppl=4.09, wps=72054.9, ups=5.3, wpb=13589, bsz=685.1, num_updates=25700, lr=0.000394515, gnorm=0.728, train_wall=19, gb_free=19, wall=5054
2023-06-29 19:06:14 | INFO | train_inner | epoch 047:    224 / 556 loss=3.886, nll_loss=2.104, ppl=4.3, wps=71450.4, ups=5.3, wpb=13470.7, bsz=673.1, num_updates=25800, lr=0.00039375, gnorm=0.753, train_wall=19, gb_free=19.8, wall=5073
2023-06-29 19:06:33 | INFO | train_inner | epoch 047:    324 / 556 loss=3.919, nll_loss=2.144, ppl=4.42, wps=71585.5, ups=5.25, wpb=13634.8, bsz=690.6, num_updates=25900, lr=0.000392989, gnorm=0.729, train_wall=19, gb_free=19.2, wall=5092
2023-06-29 19:06:52 | INFO | train_inner | epoch 047:    424 / 556 loss=3.958, nll_loss=2.188, ppl=4.56, wps=72075.2, ups=5.33, wpb=13519.4, bsz=673, num_updates=26000, lr=0.000392232, gnorm=0.745, train_wall=18, gb_free=19.2, wall=5111
2023-06-29 19:07:10 | INFO | train_inner | epoch 047:    524 / 556 loss=3.989, nll_loss=2.227, ppl=4.68, wps=71274.4, ups=5.31, wpb=13433.2, bsz=718.3, num_updates=26100, lr=0.00039148, gnorm=0.754, train_wall=19, gb_free=19, wall=5130
2023-06-29 19:07:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:07:17 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:07:17 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:07:18 | INFO | valid | epoch 047 | valid on 'valid' subset | loss 5.813 | nll_loss 4.212 | ppl 18.53 | wps 211651 | wpb 9430 | bsz 473.9 | num_updates 26132 | best_loss 5.524
2023-06-29 19:07:18 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 26132 updates
2023-06-29 19:07:18 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint47.pt
2023-06-29 19:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint47.pt
2023-06-29 19:07:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint47.pt (epoch 47 @ 26132 updates, score 5.813) (writing took 2.685326274484396 seconds)
2023-06-29 19:07:20 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2023-06-29 19:07:20 | INFO | train | epoch 047 | loss 3.915 | nll_loss 2.138 | ppl 4.4 | wps 69156.2 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 26132 | lr 0.00039124 | gnorm 0.741 | train_wall 104 | gb_free 18.9 | wall 5140
2023-06-29 19:07:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:07:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:07:20 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:07:20 | INFO | fairseq.trainer | begin training epoch 48
2023-06-29 19:07:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:07:33 | INFO | train_inner | epoch 048:     68 / 556 loss=3.854, nll_loss=2.067, ppl=4.19, wps=59950, ups=4.36, wpb=13734.3, bsz=692.2, num_updates=26200, lr=0.000390732, gnorm=0.716, train_wall=19, gb_free=19.2, wall=5152
2023-06-29 19:07:52 | INFO | train_inner | epoch 048:    168 / 556 loss=3.85, nll_loss=2.061, ppl=4.17, wps=71614.7, ups=5.33, wpb=13444.9, bsz=669.6, num_updates=26300, lr=0.000389989, gnorm=0.751, train_wall=18, gb_free=19.4, wall=5171
2023-06-29 19:08:11 | INFO | train_inner | epoch 048:    268 / 556 loss=3.889, nll_loss=2.106, ppl=4.31, wps=71266.8, ups=5.3, wpb=13439, bsz=645.9, num_updates=26400, lr=0.000389249, gnorm=0.733, train_wall=19, gb_free=19.7, wall=5190
2023-06-29 19:08:30 | INFO | train_inner | epoch 048:    368 / 556 loss=3.923, nll_loss=2.149, ppl=4.44, wps=71542.8, ups=5.27, wpb=13574.8, bsz=686.6, num_updates=26500, lr=0.000388514, gnorm=0.733, train_wall=19, gb_free=19.5, wall=5209
2023-06-29 19:08:49 | INFO | train_inner | epoch 048:    468 / 556 loss=3.948, nll_loss=2.179, ppl=4.53, wps=72667.5, ups=5.33, wpb=13639, bsz=704.3, num_updates=26600, lr=0.000387783, gnorm=0.756, train_wall=19, gb_free=19.2, wall=5228
2023-06-29 19:09:05 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:09:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:09:05 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:09:06 | INFO | valid | epoch 048 | valid on 'valid' subset | loss 5.824 | nll_loss 4.232 | ppl 18.79 | wps 212271 | wpb 9430 | bsz 473.9 | num_updates 26688 | best_loss 5.524
2023-06-29 19:09:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 26688 updates
2023-06-29 19:09:06 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint48.pt
2023-06-29 19:09:08 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint48.pt
2023-06-29 19:09:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint48.pt (epoch 48 @ 26688 updates, score 5.824) (writing took 2.9198703728616238 seconds)
2023-06-29 19:09:09 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2023-06-29 19:09:09 | INFO | train | epoch 048 | loss 3.9 | nll_loss 2.121 | ppl 4.35 | wps 69216.9 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 26688 | lr 0.000387144 | gnorm 0.74 | train_wall 103 | gb_free 18.9 | wall 5248
2023-06-29 19:09:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:09:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:09:09 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:09:09 | INFO | fairseq.trainer | begin training epoch 49
2023-06-29 19:09:09 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:09:12 | INFO | train_inner | epoch 049:     12 / 556 loss=3.954, nll_loss=2.185, ppl=4.55, wps=58992.5, ups=4.36, wpb=13518.6, bsz=667, num_updates=26700, lr=0.000387056, gnorm=0.758, train_wall=19, gb_free=19.8, wall=5251
2023-06-29 19:09:30 | INFO | train_inner | epoch 049:    112 / 556 loss=3.795, nll_loss=1.999, ppl=4, wps=72253.7, ups=5.3, wpb=13621.7, bsz=699.2, num_updates=26800, lr=0.000386334, gnorm=0.705, train_wall=19, gb_free=18.9, wall=5270
2023-06-29 19:09:49 | INFO | train_inner | epoch 049:    212 / 556 loss=3.846, nll_loss=2.059, ppl=4.17, wps=71174.7, ups=5.29, wpb=13457.5, bsz=699.4, num_updates=26900, lr=0.000385615, gnorm=0.758, train_wall=19, gb_free=19, wall=5289
2023-06-29 19:10:08 | INFO | train_inner | epoch 049:    312 / 556 loss=3.878, nll_loss=2.096, ppl=4.27, wps=71843.3, ups=5.32, wpb=13495.2, bsz=669.6, num_updates=27000, lr=0.0003849, gnorm=0.742, train_wall=19, gb_free=19.7, wall=5307
2023-06-29 19:10:27 | INFO | train_inner | epoch 049:    412 / 556 loss=3.923, nll_loss=2.149, ppl=4.44, wps=72680.9, ups=5.26, wpb=13825.9, bsz=682.7, num_updates=27100, lr=0.000384189, gnorm=0.725, train_wall=19, gb_free=19.2, wall=5326
2023-06-29 19:10:46 | INFO | train_inner | epoch 049:    512 / 556 loss=3.948, nll_loss=2.178, ppl=4.52, wps=70945.1, ups=5.27, wpb=13465.9, bsz=670.6, num_updates=27200, lr=0.000383482, gnorm=0.759, train_wall=19, gb_free=19.1, wall=5345
2023-06-29 19:10:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:10:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:10:54 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:10:55 | INFO | valid | epoch 049 | valid on 'valid' subset | loss 5.834 | nll_loss 4.238 | ppl 18.87 | wps 211202 | wpb 9430 | bsz 473.9 | num_updates 27244 | best_loss 5.524
2023-06-29 19:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 27244 updates
2023-06-29 19:10:55 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint49.pt
2023-06-29 19:10:57 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint49.pt
2023-06-29 19:10:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint49.pt (epoch 49 @ 27244 updates, score 5.834) (writing took 2.9688521176576614 seconds)
2023-06-29 19:10:58 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2023-06-29 19:10:58 | INFO | train | epoch 049 | loss 3.885 | nll_loss 2.104 | ppl 4.3 | wps 69028.2 | ups 5.09 | wpb 13556 | bsz 681.8 | num_updates 27244 | lr 0.000383173 | gnorm 0.74 | train_wall 104 | gb_free 19.3 | wall 5358
2023-06-29 19:10:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:10:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:10:59 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:10:59 | INFO | fairseq.trainer | begin training epoch 50
2023-06-29 19:10:59 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:11:09 | INFO | train_inner | epoch 050:     56 / 556 loss=3.86, nll_loss=2.074, ppl=4.21, wps=57739, ups=4.3, wpb=13440.2, bsz=684.6, num_updates=27300, lr=0.00038278, gnorm=0.751, train_wall=19, gb_free=19.5, wall=5369
2023-06-29 19:11:29 | INFO | train_inner | epoch 050:    156 / 556 loss=3.824, nll_loss=2.031, ppl=4.09, wps=68950.5, ups=5.14, wpb=13407, bsz=672.3, num_updates=27400, lr=0.00038208, gnorm=0.736, train_wall=19, gb_free=19.4, wall=5388
2023-06-29 19:11:49 | INFO | train_inner | epoch 050:    256 / 556 loss=3.863, nll_loss=2.076, ppl=4.22, wps=66351.5, ups=4.89, wpb=13572.9, bsz=628.2, num_updates=27500, lr=0.000381385, gnorm=0.735, train_wall=20, gb_free=18.9, wall=5408
2023-06-29 19:12:11 | INFO | train_inner | epoch 050:    356 / 556 loss=3.87, nll_loss=2.09, ppl=4.26, wps=62737.6, ups=4.64, wpb=13522.2, bsz=732.4, num_updates=27600, lr=0.000380693, gnorm=0.741, train_wall=21, gb_free=19.2, wall=5430
2023-06-29 19:12:30 | INFO | train_inner | epoch 050:    456 / 556 loss=3.904, nll_loss=2.128, ppl=4.37, wps=72555.3, ups=5.29, wpb=13727.5, bsz=696.5, num_updates=27700, lr=0.000380006, gnorm=0.745, train_wall=19, gb_free=19, wall=5449
2023-06-29 19:12:49 | INFO | train_inner | epoch 050:    556 / 556 loss=3.958, nll_loss=2.19, ppl=4.56, wps=71496.3, ups=5.26, wpb=13592.8, bsz=670.6, num_updates=27800, lr=0.000379322, gnorm=0.759, train_wall=19, gb_free=18.9, wall=5468
2023-06-29 19:12:49 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:12:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:12:49 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:12:50 | INFO | valid | epoch 050 | valid on 'valid' subset | loss 5.85 | nll_loss 4.245 | ppl 18.97 | wps 210477 | wpb 9430 | bsz 473.9 | num_updates 27800 | best_loss 5.524
2023-06-29 19:12:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 27800 updates
2023-06-29 19:12:50 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint50.pt
2023-06-29 19:12:51 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint50.pt
2023-06-29 19:12:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint50.pt (epoch 50 @ 27800 updates, score 5.85) (writing took 2.4956355802714825 seconds)
2023-06-29 19:12:52 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2023-06-29 19:12:52 | INFO | train | epoch 050 | loss 3.872 | nll_loss 2.089 | ppl 4.25 | wps 66150.2 | ups 4.88 | wpb 13556 | bsz 681.8 | num_updates 27800 | lr 0.000379322 | gnorm 0.743 | train_wall 109 | gb_free 18.9 | wall 5472
2023-06-29 19:12:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:12:52 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:12:52 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:12:52 | INFO | fairseq.trainer | begin training epoch 51
2023-06-29 19:12:52 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:13:11 | INFO | train_inner | epoch 051:    100 / 556 loss=3.766, nll_loss=1.964, ppl=3.9, wps=60348.2, ups=4.43, wpb=13614.5, bsz=704.2, num_updates=27900, lr=0.000378641, gnorm=0.741, train_wall=19, gb_free=19.4, wall=5491
2023-06-29 19:13:30 | INFO | train_inner | epoch 051:    200 / 556 loss=3.818, nll_loss=2.025, ppl=4.07, wps=72406.2, ups=5.33, wpb=13591.4, bsz=681.7, num_updates=28000, lr=0.000377964, gnorm=0.758, train_wall=19, gb_free=19.5, wall=5509
2023-06-29 19:13:49 | INFO | train_inner | epoch 051:    300 / 556 loss=3.865, nll_loss=2.08, ppl=4.23, wps=72065.1, ups=5.32, wpb=13542.3, bsz=668.6, num_updates=28100, lr=0.000377291, gnorm=0.782, train_wall=19, gb_free=19.2, wall=5528
2023-06-29 19:14:08 | INFO | train_inner | epoch 051:    400 / 556 loss=3.883, nll_loss=2.103, ppl=4.3, wps=72051.5, ups=5.29, wpb=13627.1, bsz=699.2, num_updates=28200, lr=0.000376622, gnorm=0.744, train_wall=19, gb_free=19.8, wall=5547
2023-06-29 19:14:27 | INFO | train_inner | epoch 051:    500 / 556 loss=3.912, nll_loss=2.137, ppl=4.4, wps=70665, ups=5.3, wpb=13320.5, bsz=669.1, num_updates=28300, lr=0.000375956, gnorm=0.763, train_wall=19, gb_free=19.6, wall=5566
2023-06-29 19:14:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:14:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:14:37 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:14:38 | INFO | valid | epoch 051 | valid on 'valid' subset | loss 5.848 | nll_loss 4.251 | ppl 19.04 | wps 214246 | wpb 9430 | bsz 473.9 | num_updates 28356 | best_loss 5.524
2023-06-29 19:14:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 28356 updates
2023-06-29 19:14:38 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint51.pt
2023-06-29 19:14:40 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint51.pt
2023-06-29 19:14:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint51.pt (epoch 51 @ 28356 updates, score 5.848) (writing took 2.913539282977581 seconds)
2023-06-29 19:14:41 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2023-06-29 19:14:41 | INFO | train | epoch 051 | loss 3.858 | nll_loss 2.073 | ppl 4.21 | wps 69297.4 | ups 5.11 | wpb 13556 | bsz 681.8 | num_updates 28356 | lr 0.000375584 | gnorm 0.759 | train_wall 103 | gb_free 19.2 | wall 5580
2023-06-29 19:14:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:14:41 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:14:41 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:14:41 | INFO | fairseq.trainer | begin training epoch 52
2023-06-29 19:14:41 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:14:50 | INFO | train_inner | epoch 052:     44 / 556 loss=3.854, nll_loss=2.068, ppl=4.19, wps=59329.8, ups=4.36, wpb=13592.5, bsz=688.3, num_updates=28400, lr=0.000375293, gnorm=0.75, train_wall=19, gb_free=19.2, wall=5589
2023-06-29 19:15:08 | INFO | train_inner | epoch 052:    144 / 556 loss=3.781, nll_loss=1.981, ppl=3.95, wps=71416.6, ups=5.33, wpb=13393.8, bsz=676.6, num_updates=28500, lr=0.000374634, gnorm=0.78, train_wall=18, gb_free=19.1, wall=5608
2023-06-29 19:15:27 | INFO | train_inner | epoch 052:    244 / 556 loss=3.83, nll_loss=2.039, ppl=4.11, wps=72643.4, ups=5.31, wpb=13688.1, bsz=669.4, num_updates=28600, lr=0.000373979, gnorm=0.747, train_wall=19, gb_free=18.9, wall=5626
2023-06-29 19:15:46 | INFO | train_inner | epoch 052:    344 / 556 loss=3.854, nll_loss=2.067, ppl=4.19, wps=71235, ups=5.26, wpb=13530.7, bsz=640.3, num_updates=28700, lr=0.000373327, gnorm=0.737, train_wall=19, gb_free=19.1, wall=5645
2023-06-29 19:16:05 | INFO | train_inner | epoch 052:    444 / 556 loss=3.887, nll_loss=2.107, ppl=4.31, wps=71362.7, ups=5.29, wpb=13497.9, bsz=681.8, num_updates=28800, lr=0.000372678, gnorm=0.779, train_wall=19, gb_free=19, wall=5664
2023-06-29 19:16:24 | INFO | train_inner | epoch 052:    544 / 556 loss=3.916, nll_loss=2.143, ppl=4.42, wps=72217.4, ups=5.28, wpb=13682.5, bsz=693.5, num_updates=28900, lr=0.000372033, gnorm=0.769, train_wall=19, gb_free=19.8, wall=5683
2023-06-29 19:16:26 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:16:26 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:16:26 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:16:27 | INFO | valid | epoch 052 | valid on 'valid' subset | loss 5.858 | nll_loss 4.27 | ppl 19.29 | wps 215721 | wpb 9430 | bsz 473.9 | num_updates 28912 | best_loss 5.524
2023-06-29 19:16:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 28912 updates
2023-06-29 19:16:27 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint52.pt
2023-06-29 19:16:29 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint52.pt
2023-06-29 19:16:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint52.pt (epoch 52 @ 28912 updates, score 5.858) (writing took 2.8535019904375076 seconds)
2023-06-29 19:16:30 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2023-06-29 19:16:30 | INFO | train | epoch 052 | loss 3.845 | nll_loss 2.058 | ppl 4.16 | wps 69105.4 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 28912 | lr 0.000371955 | gnorm 0.76 | train_wall 104 | gb_free 19.6 | wall 5689
2023-06-29 19:16:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:16:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:16:30 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:16:30 | INFO | fairseq.trainer | begin training epoch 53
2023-06-29 19:16:30 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:16:47 | INFO | train_inner | epoch 053:     88 / 556 loss=3.752, nll_loss=1.948, ppl=3.86, wps=59100.6, ups=4.37, wpb=13537, bsz=700.3, num_updates=29000, lr=0.000371391, gnorm=0.742, train_wall=19, gb_free=20.2, wall=5706
2023-06-29 19:17:06 | INFO | train_inner | epoch 053:    188 / 556 loss=3.789, nll_loss=1.992, ppl=3.98, wps=71215.3, ups=5.25, wpb=13568.1, bsz=681.8, num_updates=29100, lr=0.000370752, gnorm=0.753, train_wall=19, gb_free=19.1, wall=5725
2023-06-29 19:17:25 | INFO | train_inner | epoch 053:    288 / 556 loss=3.818, nll_loss=2.026, ppl=4.07, wps=72138.9, ups=5.32, wpb=13568.1, bsz=678.2, num_updates=29200, lr=0.000370117, gnorm=0.765, train_wall=19, gb_free=19.6, wall=5744
2023-06-29 19:17:44 | INFO | train_inner | epoch 053:    388 / 556 loss=3.865, nll_loss=2.082, ppl=4.23, wps=71677.3, ups=5.32, wpb=13482.3, bsz=675, num_updates=29300, lr=0.000369484, gnorm=0.758, train_wall=19, gb_free=19.3, wall=5763
2023-06-29 19:18:02 | INFO | train_inner | epoch 053:    488 / 556 loss=3.894, nll_loss=2.116, ppl=4.34, wps=72804.3, ups=5.33, wpb=13669.4, bsz=696.2, num_updates=29400, lr=0.000368856, gnorm=0.765, train_wall=19, gb_free=19, wall=5782
2023-06-29 19:18:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:18:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:18:15 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:18:16 | INFO | valid | epoch 053 | valid on 'valid' subset | loss 5.872 | nll_loss 4.281 | ppl 19.44 | wps 211925 | wpb 9430 | bsz 473.9 | num_updates 29468 | best_loss 5.524
2023-06-29 19:18:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 29468 updates
2023-06-29 19:18:16 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint53.pt
2023-06-29 19:18:18 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint53.pt
2023-06-29 19:18:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint53.pt (epoch 53 @ 29468 updates, score 5.872) (writing took 3.0305600613355637 seconds)
2023-06-29 19:18:19 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2023-06-29 19:18:19 | INFO | train | epoch 053 | loss 3.832 | nll_loss 2.043 | ppl 4.12 | wps 69079.8 | ups 5.1 | wpb 13556 | bsz 681.8 | num_updates 29468 | lr 0.00036843 | gnorm 0.758 | train_wall 103 | gb_free 19.1 | wall 5799
2023-06-29 19:18:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:18:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:18:19 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:18:19 | INFO | fairseq.trainer | begin training epoch 54
2023-06-29 19:18:19 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:18:25 | INFO | train_inner | epoch 054:     32 / 556 loss=3.844, nll_loss=2.057, ppl=4.16, wps=58901.8, ups=4.34, wpb=13574, bsz=676.7, num_updates=29500, lr=0.00036823, gnorm=0.758, train_wall=19, gb_free=19.3, wall=5805
2023-06-29 19:18:44 | INFO | train_inner | epoch 054:    132 / 556 loss=3.739, nll_loss=1.933, ppl=3.82, wps=72059.1, ups=5.26, wpb=13687.2, bsz=679.3, num_updates=29600, lr=0.000367607, gnorm=0.73, train_wall=19, gb_free=19.2, wall=5824
2023-06-29 19:19:03 | INFO | train_inner | epoch 054:    232 / 556 loss=3.797, nll_loss=2.002, ppl=4, wps=71327.8, ups=5.28, wpb=13506.1, bsz=684.9, num_updates=29700, lr=0.000366988, gnorm=0.771, train_wall=19, gb_free=19.4, wall=5843
2023-06-29 19:19:22 | INFO | train_inner | epoch 054:    332 / 556 loss=3.83, nll_loss=2.042, ppl=4.12, wps=71579.4, ups=5.3, wpb=13496.2, bsz=699.3, num_updates=29800, lr=0.000366372, gnorm=0.747, train_wall=19, gb_free=19.2, wall=5861
2023-06-29 19:19:41 | INFO | train_inner | epoch 054:    432 / 556 loss=3.86, nll_loss=2.077, ppl=4.22, wps=71926, ups=5.33, wpb=13484.8, bsz=704.6, num_updates=29900, lr=0.000365758, gnorm=0.76, train_wall=18, gb_free=19.1, wall=5880
2023-06-29 19:20:00 | INFO | train_inner | epoch 054:    532 / 556 loss=3.88, nll_loss=2.099, ppl=4.28, wps=72255.1, ups=5.32, wpb=13580.7, bsz=646.6, num_updates=30000, lr=0.000365148, gnorm=0.756, train_wall=19, gb_free=19.3, wall=5899
2023-06-29 19:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-06-29 19:20:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:20:04 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:20:05 | INFO | valid | epoch 054 | valid on 'valid' subset | loss 5.879 | nll_loss 4.285 | ppl 19.49 | wps 213095 | wpb 9430 | bsz 473.9 | num_updates 30024 | best_loss 5.524
2023-06-29 19:20:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 30024 updates
2023-06-29 19:20:05 | INFO | fairseq.trainer | Saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint54.pt
2023-06-29 19:20:07 | INFO | fairseq.trainer | Finished saving checkpoint to /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint54.pt
2023-06-29 19:20:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /root/autodl-tmp/NLP_hw3/nmt/models/TED/checkpoints/checkpoint54.pt (epoch 54 @ 30024 updates, score 5.879) (writing took 2.4899837151169777 seconds)
2023-06-29 19:20:08 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2023-06-29 19:20:08 | INFO | train | epoch 054 | loss 3.819 | nll_loss 2.028 | ppl 4.08 | wps 69423.5 | ups 5.12 | wpb 13556 | bsz 681.8 | num_updates 30024 | lr 0.000365002 | gnorm 0.753 | train_wall 103 | gb_free 18.9 | wall 5907
2023-06-29 19:20:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-06-29 19:20:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 556
2023-06-29 19:20:08 | WARNING | fairseq.logging.progress_bar | tensorboard not found, please install with: pip install tensorboard
2023-06-29 19:20:08 | INFO | fairseq.trainer | begin training epoch 55
2023-06-29 19:20:08 | INFO | fairseq_cli.train | Start iterating over samples
2023-06-29 19:20:22 | INFO | train_inner | epoch 055:     76 / 556 loss=3.766, nll_loss=1.964, ppl=3.9, wps=59502.2, ups=4.43, wpb=13418, bsz=659.1, num_updates=30100, lr=0.000364541, gnorm=0.757, train_wall=19, gb_free=19.4, wall=5921
